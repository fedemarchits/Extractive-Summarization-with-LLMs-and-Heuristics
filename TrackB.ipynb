{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8d5ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicomarchi/Desktop/BigData&TextMining/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/federicomarchi/Desktop/BigData&TextMining/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pip install datasets\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91f39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_abstractive = load_dataset(\"sobamchan/aclsum\", \"abstractive\", split=\"test\")\n",
    "dataset_extractive = load_dataset(\"sobamchan/aclsum\", \"extractive\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4beb801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'E09-1056', 'document': 'Handling terminology is an important matter in a translation workflow . However , current Machine Translation ( MT ) systems do not yet propose anything proactive upon tools which assist in managing terminological databases . In this work , we investigate several enhancements to analogical learning and test our implementation on translating medical terms . We show that the analogical engine works equally well when translating from and into a morphologically rich language , or when dealing with language pairs written in different scripts . Combining it with a phrasebased statistical engine leads to significant improvements . If machine translation is to meet commercial needs , it must offer a sensible approach to translating terms . Currently , MT systems offer at best database management tools which allow a human ( typically a translator , a terminologist or even the vendor of the system ) to specify bilingual terminological entries . More advanced tools are meant to identify inconsistencies in terminological translations and might prove useful in controlledlanguage situations ( Itagaki et al . , 2007 ) . One approach to translate terms consists in using a domain-specific parallel corpus with standard alignment techniques ( Brown et al . , 1993 ) to mine new translations . Massive amounts of parallel data are certainly available in several pairs of languages for domains such as parliament debates or the like . However , having at our disposal a domain-specific ( e.g. computer science ) bitext with an adequate coverage is another issue . One might argue that domain-specific comparable ( or perhaps unrelated ) corpora are easier to acquire , in which case context-vector techniques ( Rapp , 1995 ; Fung and McKeown , 1997 ) can be used to identify the translation of terms . We certainly agree with that point of view to a certain extent , but as discussed by Morin et al . ( 2007 ) , for many specific domains and pairs of languages , such resources simply do not exist . Furthermore , the task of translation identification is more difficult and error-prone . Analogical learning has recently regained some interest in the NLP community . Lepage and Denoual ( 2005 ) proposed a machine translation system entirely based on the concept of formal analogy , that is , analogy on forms . Stroppa and Yvon ( 2005 ) applied analogical learning to several morphological tasks also involving analogies on words . Langlais and Patry ( 2007 ) applied it to the task of translating unknown words in several European languages , an idea investigated as well by Denoual ( 2007 ) for a Japanese to English translation task . In this study , we improve the state-of-the-art of analogical learning by ( i ) proposing a simple yet effective implementation of an analogical solver ; ( ii ) proposing an efficient solution to the search issue embedded in analogical learning , ( iii ) investigating whether a classifier can be trained to recognize bad candidates produced by analogical learning . We evaluate our analogical engine on the task of translating terms of the medical domain ; a domain well-known for its tendency to create new words , many of which being complex lexical constructions . Our experiments involve five language pairs , including languages with very different morphological systems . In the remainder of this paper , we first present in Section 2 the principle of analogical learning . Practical issues in analogical learning are discussed in Section 3 along with our solutions . In Section 4 , we report on experiments we conducted with our analogical device . We conclude this study and discuss future work in Section 5 . In this study , we proposed solutions to practical issues involved in analogical learning . A simple yet effective implementation of a solver is described . A search strategy is proposed which outperforms the one described in ( Langlais and Patry , 2007 ) . Also , we showed that a classifier trained to select good candidate translations outperforms the most-frequently-generated heuristic used in several works on analogical learning . Our analogical device was used to translate medical terms in different language pairs . The approach rates comparably across the 10 translation directions we considered . In particular , we do not see a drop in performance when translating into a morphology rich language ( such as Finnish ) , or when translating into languages with different scripts . Averaged over all translation directions , the best variant could translate in first position 21 % of the terms with a precision of 57 % , while at best , one could translate 30 % of the terms with a perfect precision . We show that the analogical translations are of better quality than those produced by a phrase-based engine trained at the character level , albeit with much lower recall . A straightforward combination of both approaches led an improvement of 5.3 BLEU points over the SMT alone . Better SMT performance could be obtained with a system based on morphemes , see for instance ( Toutanova et al . , 2008 ) . However , since lists of morphemes specific to the medical domain do not exist for all the languages pairs we considered here , unsupervised methods for acquiring morphemes would be necessary , which is left as a future work . In any case , this comparison is meaningful , since both the SMT and the analogical device work at the character level . This work opens up several avenues . First , we will test our approach on terminologies from different domains , varying the size of the training material . Second , analyzing the segmentation induced by analogical learning would be interesting . Third , we need to address the problem of combining the translations produced by analogy into a front-end statistical translation engine . Last , there is no reason to constrain ourselves to translating terminology only . We targeted this task in the first place , because terminology typically plugs translation systems , but we think that analogical learning could be useful for translating infrequent entities .', 'challenge': 'Existing machine translation systems do not manage domain-specific terms mainly due to the expensiveness for certain language pairs and domains.', 'approach': 'They propose simple methods to improve existing analogy solvers and apply them to the translation of medial terms.', 'outcome': 'The proposed analogy solvers significantly improve machine translation of the medical domain for morphologically rich languages and language pairs in different scripts.'}\n",
      "{'id': 'E09-1056', 'source_sentences': ['Handling terminology is an important matter in a translation workflow .', 'However , current Machine Translation ( MT ) systems do not yet propose anything proactive upon tools which assist in managing terminological databases .', 'In this work , we investigate several enhancements to analogical learning and test our implementation on translating medical terms .', 'We show that the analogical engine works equally well when translating from and into a morphologically rich language , or when dealing with language pairs written in different scripts .', 'Combining it with a phrasebased statistical engine leads to significant improvements .', 'If machine translation is to meet commercial needs , it must offer a sensible approach to translating terms .', 'Currently , MT systems offer at best database management tools which allow a human ( typically a translator , a terminologist or even the vendor of the system ) to specify bilingual terminological entries .', 'More advanced tools are meant to identify inconsistencies in terminological translations and might prove useful in controlledlanguage situations ( Itagaki et al . , 2007 ) .', 'One approach to translate terms consists in using a domain-specific parallel corpus with standard alignment techniques ( Brown et al . , 1993 ) to mine new translations .', 'Massive amounts of parallel data are certainly available in several pairs of languages for domains such as parliament debates or the like .', 'However , having at our disposal a domain-specific ( e.g. computer science ) bitext with an adequate coverage is another issue .', 'One might argue that domain-specific comparable ( or perhaps unrelated ) corpora are easier to acquire , in which case context-vector techniques ( Rapp , 1995 ; Fung and McKeown , 1997 ) can be used to identify the translation of terms .', 'We certainly agree with that point of view to a certain extent , but as discussed by Morin et al . ( 2007 ) , for many specific domains and pairs of languages , such resources simply do not exist .', 'Furthermore , the task of translation identification is more difficult and error-prone .', 'Analogical learning has recently regained some interest in the NLP community .', 'Lepage and Denoual ( 2005 ) proposed a machine translation system entirely based on the concept of formal analogy , that is , analogy on forms .', 'Stroppa and Yvon ( 2005 ) applied analogical learning to several morphological tasks also involving analogies on words .', 'Langlais and Patry ( 2007 ) applied it to the task of translating unknown words in several European languages , an idea investigated as well by Denoual ( 2007 ) for a Japanese to English translation task .', 'In this study , we improve the state-of-the-art of analogical learning by ( i ) proposing a simple yet effective implementation of an analogical solver ; ( ii ) proposing an efficient solution to the search issue embedded in analogical learning , ( iii ) investigating whether a classifier can be trained to recognize bad candidates produced by analogical learning .', 'We evaluate our analogical engine on the task of translating terms of the medical domain ; a domain well-known for its tendency to create new words , many of which being complex lexical constructions .', 'Our experiments involve five language pairs , including languages with very different morphological systems .', 'In the remainder of this paper , we first present in Section 2 the principle of analogical learning .', 'Practical issues in analogical learning are discussed in Section 3 along with our solutions .', 'In Section 4 , we report on experiments we conducted with our analogical device .', 'We conclude this study and discuss future work in Section 5 .', 'In this study , we proposed solutions to practical issues involved in analogical learning .', 'A simple yet effective implementation of a solver is described .', 'A search strategy is proposed which outperforms the one described in ( Langlais and Patry , 2007 ) .', 'Also , we showed that a classifier trained to select good candidate translations outperforms the most-frequently-generated heuristic used in several works on analogical learning .', 'Our analogical device was used to translate medical terms in different language pairs .', 'The approach rates comparably across the 10 translation directions we considered .', 'In particular , we do not see a drop in performance when translating into a morphology rich language ( such as Finnish ) , or when translating into languages with different scripts .', 'Averaged over all translation directions , the best variant could translate in first position 21 % of the terms with a precision of 57 % , while at best , one could translate 30 % of the terms with a perfect precision .', 'We show that the analogical translations are of better quality than those produced by a phrase-based engine trained at the character level , albeit with much lower recall .', 'A straightforward combination of both approaches led an improvement of 5.3 BLEU points over the SMT alone .', 'Better SMT performance could be obtained with a system based on morphemes , see for instance ( Toutanova et al . , 2008 ) .', 'However , since lists of morphemes specific to the medical domain do not exist for all the languages pairs we considered here , unsupervised methods for acquiring morphemes would be necessary , which is left as a future work .', 'In any case , this comparison is meaningful , since both the SMT and the analogical device work at the character level .', 'This work opens up several avenues .', 'First , we will test our approach on terminologies from different domains , varying the size of the training material .', 'Second , analyzing the segmentation induced by analogical learning would be interesting .', 'Third , we need to address the problem of combining the translations produced by analogy into a front-end statistical translation engine .', 'Last , there is no reason to constrain ourselves to translating terminology only .', 'We targeted this task in the first place , because terminology typically plugs translation systems , but we think that analogical learning could be useful for translating infrequent entities .'], 'challenge_sentences': ['Handling terminology is an important matter in a translation workflow .', 'However , current Machine Translation ( MT ) systems do not yet propose anything proactive upon tools which assist in managing terminological databases .', 'Currently , MT systems offer at best database management tools which allow a human ( typically a translator , a terminologist or even the vendor of the system ) to specify bilingual terminological entries .', 'However , having at our disposal a domain-specific ( e.g. computer science ) bitext with an adequate coverage is another issue .'], 'approach_sentences': ['In this work , we investigate several enhancements to analogical learning and test our implementation on translating medical terms .', 'Analogical learning has recently regained some interest in the NLP community .', 'In this study , we improve the state-of-the-art of analogical learning by ( i ) proposing a simple yet effective implementation of an analogical solver ; ( ii ) proposing an efficient solution to the search issue embedded in analogical learning , ( iii ) investigating whether a classifier can be trained to recognize bad candidates produced by analogical learning .', 'In this study , we proposed solutions to practical issues involved in analogical learning .', 'A simple yet effective implementation of a solver is described .'], 'outcome_sentences': ['We show that the analogical engine works equally well when translating from and into a morphologically rich language , or when dealing with language pairs written in different scripts .', 'Combining it with a phrasebased statistical engine leads to significant improvements .', 'We evaluate our analogical engine on the task of translating terms of the medical domain ; a domain well-known for its tendency to create new words , many of which being complex lexical constructions .', 'Our experiments involve five language pairs , including languages with very different morphological systems .', 'Our analogical device was used to translate medical terms in different language pairs .', 'The approach rates comparably across the 10 translation directions we considered .'], 'challenge_labels': [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'approach_labels': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'outcome_labels': [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_abstractive[0])\n",
    "print(dataset_extractive[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fd0421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Handling terminology is an important matter in a translation workflow .', 'However , current Machine Translation ( MT ) systems do not yet propose anything proactive upon tools which assist in managing terminological databases .', 'In this work , we investigate several enhancements to analogical learning and test our implementation on translating medical terms .', 'We show that the analogical engine works equally well when translating from and into a morphologically rich language , or when dealing with language pairs written in different scripts .', 'Combining it with a phrasebased statistical engine leads to significant improvements .', 'If machine translation is to meet commercial needs , it must offer a sensible approach to translating terms .', 'Currently , MT systems offer at best database management tools which allow a human ( typically a translator , a terminologist or even the vendor of the system ) to specify bilingual terminological entries .', 'More advanced tools are meant to identify inconsistencies in terminological translations and might prove useful in controlledlanguage situations ( Itagaki et al . , 2007 ) .', 'One approach to translate terms consists in using a domain-specific parallel corpus with standard alignment techniques ( Brown et al . , 1993 ) to mine new translations .', 'Massive amounts of parallel data are certainly available in several pairs of languages for domains such as parliament debates or the like .', 'However , having at our disposal a domain-specific ( e.g. computer science ) bitext with an adequate coverage is another issue .', 'One might argue that domain-specific comparable ( or perhaps unrelated ) corpora are easier to acquire , in which case context-vector techniques ( Rapp , 1995 ; Fung and McKeown , 1997 ) can be used to identify the translation of terms .', 'We certainly agree with that point of view to a certain extent , but as discussed by Morin et al . ( 2007 ) , for many specific domains and pairs of languages , such resources simply do not exist .', 'Furthermore , the task of translation identification is more difficult and error-prone .', 'Analogical learning has recently regained some interest in the NLP community .', 'Lepage and Denoual ( 2005 ) proposed a machine translation system entirely based on the concept of formal analogy , that is , analogy on forms .', 'Stroppa and Yvon ( 2005 ) applied analogical learning to several morphological tasks also involving analogies on words .', 'Langlais and Patry ( 2007 ) applied it to the task of translating unknown words in several European languages , an idea investigated as well by Denoual ( 2007 ) for a Japanese to English translation task .', 'In this study , we improve the state-of-the-art of analogical learning by ( i ) proposing a simple yet effective implementation of an analogical solver ; ( ii ) proposing an efficient solution to the search issue embedded in analogical learning , ( iii ) investigating whether a classifier can be trained to recognize bad candidates produced by analogical learning .', 'We evaluate our analogical engine on the task of translating terms of the medical domain ; a domain well-known for its tendency to create new words , many of which being complex lexical constructions .', 'Our experiments involve five language pairs , including languages with very different morphological systems .', 'In the remainder of this paper , we first present in Section 2 the principle of analogical learning .', 'Practical issues in analogical learning are discussed in Section 3 along with our solutions .', 'In Section 4 , we report on experiments we conducted with our analogical device .', 'We conclude this study and discuss future work in Section 5 .', 'In this study , we proposed solutions to practical issues involved in analogical learning .', 'A simple yet effective implementation of a solver is described .', 'A search strategy is proposed which outperforms the one described in ( Langlais and Patry , 2007 ) .', 'Also , we showed that a classifier trained to select good candidate translations outperforms the most-frequently-generated heuristic used in several works on analogical learning .', 'Our analogical device was used to translate medical terms in different language pairs .', 'The approach rates comparably across the 10 translation directions we considered .', 'In particular , we do not see a drop in performance when translating into a morphology rich language ( such as Finnish ) , or when translating into languages with different scripts .', 'Averaged over all translation directions , the best variant could translate in first position 21 % of the terms with a precision of 57 % , while at best , one could translate 30 % of the terms with a perfect precision .', 'We show that the analogical translations are of better quality than those produced by a phrase-based engine trained at the character level , albeit with much lower recall .', 'A straightforward combination of both approaches led an improvement of 5.3 BLEU points over the SMT alone .', 'Better SMT performance could be obtained with a system based on morphemes , see for instance ( Toutanova et al . , 2008 ) .', 'However , since lists of morphemes specific to the medical domain do not exist for all the languages pairs we considered here , unsupervised methods for acquiring morphemes would be necessary , which is left as a future work .', 'In any case , this comparison is meaningful , since both the SMT and the analogical device work at the character level .', 'This work opens up several avenues .', 'First , we will test our approach on terminologies from different domains , varying the size of the training material .', 'Second , analyzing the segmentation induced by analogical learning would be interesting .', 'Third , we need to address the problem of combining the translations produced by analogy into a front-end statistical translation engine .', 'Last , there is no reason to constrain ourselves to translating terminology only .', 'We targeted this task in the first place , because terminology typically plugs translation systems , but we think that analogical learning could be useful for translating infrequent entities .']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_extractive[\"source_sentences\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b94ab",
   "metadata": {},
   "source": [
    "Let's import ROUGE F-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9ff572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install evaluate absl-py nltk rouge-score\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013ba117",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32e167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possibilities for rouge parameter are:  \"rouge1\", \"rouge2\", \"rougeL\"\n",
    "def rouge_score(candidate, reference, rougex):\n",
    "    result = rouge.compute(\n",
    "        predictions=[candidate],\n",
    "        references=[reference],\n",
    "        rouge_types=[rougex]\n",
    "    )\n",
    "    r1 = result[rougex]\n",
    "    return r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e895b",
   "metadata": {},
   "source": [
    "### Let's prepare the first heuristic: **Greed Search** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90073c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_extractive_summary(sentences, abstractive_summary, max_sent=6):\n",
    "    selected = []\n",
    "    remaining = sentences[:]\n",
    "    mask = [0] * len(sentences)\n",
    "\n",
    "    while remaining and max_sent != 0: \n",
    "        best_sentence = None\n",
    "        best_score = -1\n",
    "        for sent in remaining:\n",
    "            \n",
    "            candidate_summary = \" \".join(selected + [sent])\n",
    "            r1 = rouge_score(candidate_summary, abstractive_summary, \"rouge1\")\n",
    "            if r1 > best_score:\n",
    "                best_score = r1\n",
    "                best_sentence = sent\n",
    "       \n",
    "        selected.append(best_sentence)\n",
    "        idx = sentences.index(best_sentence)\n",
    "        mask[idx] = 1\n",
    "        remaining.remove(best_sentence)\n",
    "        max_sent -= 1\n",
    "    \n",
    "    return selected, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53643e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "selected0, mask0 = greedy_extractive_summary(dataset_extractive[\"source_sentences\"][6], dataset_abstractive[\"outcome\"][6])\n",
    "\n",
    "print(len(selected0))\n",
    "print(len(dataset_extractive[\"outcome_sentences\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523eb8c5",
   "metadata": {},
   "source": [
    "### Let's now define the loop function which computes all the extractive summaries given the abstractive ones (**only outcomes so far**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18be9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_heuristic_to_dataset(heuristic_fn, docs_sentences, abstractive_summaries):\n",
    "    selected_list = []\n",
    "    masks_list = []\n",
    "\n",
    "    for sentences, abs_summary in zip(docs_sentences, abstractive_summaries):\n",
    "        selected, mask = heuristic_fn(sentences, abs_summary)\n",
    "        selected_list.append(selected)\n",
    "        masks_list.append(mask)\n",
    "    \n",
    "    return selected_list, masks_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb5f3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_list, masks_list = apply_heuristic_to_dataset(greedy_extractive_summary, list(dataset_extractive[\"source_sentences\"]), list(dataset_abstractive[\"outcome\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53a548",
   "metadata": {},
   "source": [
    "### Let's make a function which, for each document, concatenates the sentences we have extracted from the selected list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59edf94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_concatenation(sentence_list):\n",
    "    merged_sentences = [\" \".join(inner_list) for inner_list in sentence_list]\n",
    "    return merged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29960bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentences = sentence_concatenation(selected_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af027de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_labels = sentence_concatenation(list(dataset_extractive[\"outcome_sentences\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "696ff9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(predicted_summaries, label_summaries):\n",
    "    # In case something went wrong\n",
    "    if len(predicted_summaries) != len(label_summaries):\n",
    "        return None\n",
    "    \n",
    "    r1_sum = 0\n",
    "    for pred, label in zip(predicted_summaries, label_summaries):\n",
    "        r1 = rouge_score(pred, label, \"rouge1\")\n",
    "        r1_sum += r1\n",
    "    \n",
    "    return r1_sum / len(predicted_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59a12b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ROUGE F-1 score for Greedy Search heuristic is: 0.53512\n"
     ]
    }
   ],
   "source": [
    "r1 = evaluate_performance(merged_sentences, merged_labels)\n",
    "print(f'The average ROUGE F-1 score for Greedy Search heuristic is: {round(r1, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224c9df",
   "metadata": {},
   "source": [
    "This means that only **2.26%** of unigrams in the predicted summaries effectively overlap with the labels summaries. This value is extremely low let's see if other heuristics can work better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb8094",
   "metadata": {},
   "source": [
    "### Let's do the same for **Beam Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c5659ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_extractive_summary(sentences, abstractive_summary, beam_size=3, max_sentences=6):\n",
    "    # Tuple of three items:\n",
    "    #   -   selected sentences array\n",
    "    #   -   mask of selected sentences\n",
    "    #   -   ROUGE F1 score\n",
    "    beams = [([], [0] * len(sentences), 0.0)]\n",
    "    \n",
    "    while max_sentences > 0:\n",
    "        new_beams = []\n",
    "        for selected, mask, score in beams:\n",
    "            remaining = [s for s in sentences if s not in selected]\n",
    "            \n",
    "            for sent in remaining:\n",
    "                candidate_summary = \" \".join(selected + [sent])\n",
    "                r1 = rouge_score(candidate_summary, abstractive_summary, \"rouge1\")\n",
    "                \n",
    "                # Make a new mask for this candidate\n",
    "                new_mask = mask[:]\n",
    "                idx = sentences.index(sent)\n",
    "                new_mask[idx] = 1\n",
    "                \n",
    "                new_beams.append((selected + [sent], new_mask, r1))\n",
    "        \n",
    "        # Sort by third value (ROUGE F1 score), highest score first\n",
    "        new_beams.sort(key=lambda x: x[2], reverse=True)\n",
    "        # Takes only the first beam_size elements\n",
    "        beams = new_beams[:beam_size]\n",
    "    \n",
    "    best_selected, best_mask, _ = beams[0] # Best selection\n",
    "    return best_selected, best_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7828bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_list, _ = apply_heuristic_to_dataset(beam_extractive_summary, list(dataset_extractive[\"source_sentences\"]), list(dataset_abstractive[\"outcome\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023408fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_beam = evaluate_performance(merged_sentences, merged_labels)\n",
    "print(f'The average ROUGE F-1 score for Greedy Search heuristic is: {round(r1, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5357f3",
   "metadata": {},
   "source": [
    "Implementation of extractive summarization methods combining large language models (LLMs) and heuristic sentence selection. Supports greedy and beam search strategies, lcaol and global search, multiple prompting techniques,and evaluation with ROUGE and exact-match metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
