{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "CpN6IV-eNIEg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "my access token if you want to rerun = ZHcfFFsrftNHdCIGXgzyRosnfjZOEGNlYz"
      ],
      "metadata": {
        "id": "WuQmT2lPAynA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Log in with access token\n",
        "login(token=\"hf_your_access_token_here\")"
      ],
      "metadata": {
        "id": "OVYlRvm0t3xR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU3bmgctWXyJ",
        "outputId": "97c82943-a9c5-4623-dc33-096c7ef51e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai transformers datasets rouge_score nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMt4PHlCdGzO",
        "outputId": "847d0484-1ba0-40e6-cd73-3c8315be7582"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-47GCvibWsyy"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from rouge_score import rouge_scorer\n",
        "import re\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load the dataset in extractive mode\n",
        "dataset = load_dataset(\"sobamchan/aclsum\", \"extractive\")[\"test\"]\n",
        "print(dataset[0].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmD6qDBhMVBI",
        "outputId": "3d7b863b-06e4-4990-ab67-5a21a0c86720"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['id', 'source_sentences', 'challenge_sentences', 'approach_sentences', 'outcome_sentences', 'challenge_labels', 'approach_labels', 'outcome_labels'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- to accomodate for different model, the following function is created. The Qwen model requires as a flag trust_remote_code=True, while Llama does not have this requirement\n",
        "- Llama needs to be loaded in its instruct version because when the \"standard\" version is unable to follow instructions properly, meaning that for example the output of the prompts might not be a JSON as requested but it might be a long text format. Therefore, we solve this by loading the Instruct version"
      ],
      "metadata": {
        "id": "0s__3Sy0oJYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "def load_model_and_tokenizer(model_name: str):\n",
        "    if \"Qwen\" in model_name:\n",
        "        # Qwen models require trust_remote_code=True\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, device_map=\"auto\")\n",
        "        print(\"Loaded Qwen model and tokenizer.\")\n",
        "    elif \"Llama\" in model_name:\n",
        "        # Llama models do not require trust_remote_code\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "        print(\"Loaded Llama model and tokenizer.\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model name. Please use a Qwen or Llama model.\")\n",
        "\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "N-x5hWQQnx1W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyRs1BmJnpXq",
        "outputId": "8ca710ba-50da-4307-ee5f-0a7358355c73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'source_sentences', 'challenge_sentences', 'approach_sentences', 'outcome_sentences', 'challenge_labels', 'approach_labels', 'outcome_labels'],\n",
            "    num_rows: 100\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['challenge_labels'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjDlGkgOnrvs",
        "outputId": "30e6059c-1269-4f31-9c05-6cad43495fe6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocess into sentence label pair\n",
        "\n",
        "This step is necessary as it will allow us to match the sentence itself with the label. This means that for every possible label (challenge, approach, outcome) we will store the sentences with their proper label in order to be able to evaluate the outcome accordingly.\n",
        "\n",
        "This means that every phrase in the source_sentences section of the dataset will contain a label as well as the aspect. So, the first sentence might be assigned label 1 for aspect challenge and label 0 for aspects outcome and approach."
      ],
      "metadata": {
        "id": "7Bn1qK3zxoRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_aspect_data(example, aspect):\n",
        "    return [\n",
        "        {\"sentence\": sent, \"label\": lab, \"aspect\": aspect}\n",
        "        for sent, lab in zip(example[\"source_sentences\"], example[f\"{aspect}_labels\"])\n",
        "    ]\n",
        "\n",
        "sample = prepare_aspect_data(dataset[0], \"challenge\")\n",
        "print(sample[:3])"
      ],
      "metadata": {
        "id": "8lGlxm5LzP48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e134e9-1536-4522-de2b-e30a6704ee03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'sentence': 'Handling terminology is an important matter in a translation workflow .', 'label': 1, 'aspect': 'challenge'}, {'sentence': 'However , current Machine Translation ( MT ) systems do not yet propose anything proactive upon tools which assist in managing terminological databases .', 'label': 1, 'aspect': 'challenge'}, {'sentence': 'In this work , we investigate several enhancements to analogical learning and test our implementation on translating medical terms .', 'label': 0, 'aspect': 'challenge'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_1 = prepare_aspect_data(dataset[0], \"outcome\")\n",
        "print(sample_1[:3])"
      ],
      "metadata": {
        "id": "CQqCLrUS0GZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9ea127-e422-4271-bd1f-647e421d0f3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'sentence': 'Handling terminology is an important matter in a translation workflow .', 'label': 0, 'aspect': 'outcome'}, {'sentence': 'However , current Machine Translation ( MT ) systems do not yet propose anything proactive upon tools which assist in managing terminological databases .', 'label': 0, 'aspect': 'outcome'}, {'sentence': 'In this work , we investigate several enhancements to analogical learning and test our implementation on translating medical terms .', 'label': 0, 'aspect': 'outcome'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_2 = prepare_aspect_data(dataset[0], \"approach\")\n",
        "print(sample_2[:3])"
      ],
      "metadata": {
        "id": "aA6C_6M00LFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bd8e00-6041-4360-8fd3-0aa0bc8e324e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'sentence': 'Handling terminology is an important matter in a translation workflow .', 'label': 0, 'aspect': 'approach'}, {'sentence': 'However , current Machine Translation ( MT ) systems do not yet propose anything proactive upon tools which assist in managing terminological databases .', 'label': 0, 'aspect': 'approach'}, {'sentence': 'In this work , we investigate several enhancements to analogical learning and test our implementation on translating medical terms .', 'label': 1, 'aspect': 'approach'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To apply this to the whole dataset we can use the following code snippet"
      ],
      "metadata": {
        "id": "d2H6NGZm4Wif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_triplets(example):\n",
        "    aspects = [\"challenge\", \"approach\", \"outcome\"]\n",
        "    # collect labels for each aspect\n",
        "    aspect_labels = {a: [lab for _, lab in zip(example[\"source_sentences\"], example[f\"{a}_labels\"])]\n",
        "                     for a in aspects}\n",
        "    # combine into triplets\n",
        "    triplets = []\n",
        "    for i, sent in enumerate(example[\"source_sentences\"]):\n",
        "        triplet = [aspect_labels[\"challenge\"][i],\n",
        "                   aspect_labels[\"approach\"][i],\n",
        "                   aspect_labels[\"outcome\"][i]]\n",
        "        triplets.append(triplet)\n",
        "    example[\"triplets\"] = triplets\n",
        "    return example\n",
        "\n",
        "labeled_dataset = dataset.map(add_triplets)\n",
        "\n",
        "# quick peek\n",
        "print(labeled_dataset[0][\"source_sentences\"][:10])\n",
        "print(labeled_dataset[0][\"triplets\"][:10])\n"
      ],
      "metadata": {
        "id": "sF7sNi5v4aRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b072cf-731f-4213-ee93-2d2fba9453a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Handling terminology is an important matter in a translation workflow .', 'However , current Machine Translation ( MT ) systems do not yet propose anything proactive upon tools which assist in managing terminological databases .', 'In this work , we investigate several enhancements to analogical learning and test our implementation on translating medical terms .', 'We show that the analogical engine works equally well when translating from and into a morphologically rich language , or when dealing with language pairs written in different scripts .', 'Combining it with a phrasebased statistical engine leads to significant improvements .', 'If machine translation is to meet commercial needs , it must offer a sensible approach to translating terms .', 'Currently , MT systems offer at best database management tools which allow a human ( typically a translator , a terminologist or even the vendor of the system ) to specify bilingual terminological entries .', 'More advanced tools are meant to identify inconsistencies in terminological translations and might prove useful in controlledlanguage situations ( Itagaki et al . , 2007 ) .', 'One approach to translate terms consists in using a domain-specific parallel corpus with standard alignment techniques ( Brown et al . , 1993 ) to mine new translations .', 'Massive amounts of parallel data are certainly available in several pairs of languages for domains such as parliament debates or the like .']\n",
            "[[1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 0], [1, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Function: expand one document into list of sentence dicts\n",
        "def expand_doc(example):\n",
        "    return {\n",
        "        \"sentences\": [\n",
        "            {\n",
        "                \"sentence\": sent,\n",
        "                \"label_ch\": int(ch),\n",
        "                \"label_ap\": int(ap),\n",
        "                \"label_oc\": int(oc),\n",
        "            }\n",
        "            for sent, ch, ap, oc in zip(\n",
        "                example[\"source_sentences\"],\n",
        "                example[\"challenge_labels\"],\n",
        "                example[\"approach_labels\"],\n",
        "                example[\"outcome_labels\"]\n",
        "            )\n",
        "        ]\n",
        "    }\n",
        "\n",
        "expanded = dataset.map(expand_doc)\n",
        "\n",
        "print(expanded[1][\"sentences\"][:3])\n",
        "print(f'check length: {len(expanded[1][\"sentences\"])} {len(dataset[1][\"source_sentences\"])}')\n"
      ],
      "metadata": {
        "id": "ziIkMSnM6mL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed84802-cbea-4a37-ac48-cee8089d3c1c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label_ap': 0, 'label_ch': 1, 'label_oc': 0, 'sentence': 'Reasoning about implied relationships ( e.g. paraphrastic , common sense , encyclopedic ) between pairs of words is crucial for many cross-sentence inference problems .'}, {'label_ap': 1, 'label_ch': 0, 'label_oc': 0, 'sentence': 'This paper proposes new methods for learning and using embeddings of word pairs that implicitly represent background knowledge about such relationships .'}, {'label_ap': 1, 'label_ch': 0, 'label_oc': 0, 'sentence': 'Our pairwise embeddings are computed as a compositional function on word representations , which is learned by maximizing the pointwise mutual information ( PMI ) with the contexts in which the two words cooccur .'}]\n",
            "check length: 32 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prompting techniques"
      ],
      "metadata": {
        "id": "QIuFTkim7O17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the vanilla prompt has only the task to select the most important sentences regardless of the aspect"
      ],
      "metadata": {
        "id": "TCd2Z2_VR2q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_vanilla_prompt(sentences):\n",
        "    \"\"\"\n",
        "    Generates a simple, general-purpose vanilla prompt for extractive summarization.\n",
        "    \"\"\"\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select the most important sentences from the document.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "Rules:\n",
        "- Select ONLY the most important sentences.\n",
        "- If no sentences are important, return an empty list.\n",
        "- Indices are 1-based.\n",
        "- Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "P0-yZ4b7R2DZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this second vanilla prompt instead selects the most important phrases based on the aspect, so which are the most important phrases connected to challenge, approach and outcome"
      ],
      "metadata": {
        "id": "e4VVn0iFR-q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vanilla prompt\n",
        "# needs to be called three times on the same phrase to understand the three aspects\n",
        "def vanilla_prompt(sentences, target_label):\n",
        "    # target_label ∈ {\"challenge\",\"approach\",\"outcome\"}\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select sentences that express the \"{target_label}\" aspect of the document.\n",
        "\n",
        "Aspect definitions:\n",
        "- challenge: problem, gap, limitation, unmet need, difficulty/motivation.\n",
        "- approach: method, model, system, algorithm, dataset design, procedure.\n",
        "- outcome: results, findings, improvements, metrics, performance, impact.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "Rules:\n",
        "- Select ONLY sentences that primarily express the \"{target_label}\" aspect.\n",
        "- If none match, return an empty list.\n",
        "- Indices are 1-based.\n",
        "- Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''\n"
      ],
      "metadata": {
        "id": "9juXCfSvAm9h"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Least to most** prompting technique implemented both in its aspect-based version and in the simple version. Ask the model to identify the overall purpose of the document before returning either the aspect-based sentences or the overall most important sentences."
      ],
      "metadata": {
        "id": "Ynts4oQ7S3PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def least_to_most_prompt(sentences, target_label):\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select sentences that express the \"{target_label}\" aspect of the document.\n",
        "\n",
        "Aspect definitions:\n",
        "- challenge: problem, gap, limitation, unmet need, difficulty/motivation.\n",
        "- approach: method, model, system, algorithm, dataset design, procedure.\n",
        "- outcome: results, findings, improvements, metrics, performance, impact.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "First, consider the overall purpose of the document and how each sentence contributes to it.\n",
        "Then, from that understanding, select ONLY sentences that primarily express the \"{target_label}\" aspect.\n",
        "If none match, return an empty list.\n",
        "Indices are 1-based.\n",
        "Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "t4I4Zb9nS0zT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def least_to_most_simple_prompt(sentences):\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select the most important sentences from the document.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "First, identify the main topics and key arguments of the document.\n",
        "Then, select ONLY the sentences that directly relate to those topics.\n",
        "If no sentences are important, return an empty list.\n",
        "Indices are 1-based.\n",
        "Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "sqN6CcD9S-cK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tool-augmented prompting**. Here the model is instructed to use a \"tool\" or internal function to aid its reasoning. The tool is not a real external program but a conceptual instruction within the prompt itself.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZJ5rWzyhTP50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tool_augmented_prompt(sentences, target_label):\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select sentences that express the \"{target_label}\" aspect of the document.\n",
        "\n",
        "Aspect definitions:\n",
        "- challenge: problem, gap, limitation, unmet need, difficulty/motivation.\n",
        "- approach: method, model, system, algorithm, dataset design, procedure.\n",
        "- outcome: results, findings, improvements, metrics, performance, impact.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "Instructions:\n",
        "1. For each sentence, use the internal `check_aspect(sentence, aspect)` tool.\n",
        "2. The tool's output is 'match' if the sentence primarily describes the \"{target_label}\" aspect, otherwise it is 'no_match'.\n",
        "3. List the sentences that result in a 'match'.\n",
        "4. If no sentences match, return an empty list.\n",
        "5. Indices are 1-based.\n",
        "6. Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "udvUBxJdTBwE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tool_augmented_simple_prompt(sentences):\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select the most important sentences from the document.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "Instructions:\n",
        "1. For each sentence, use the internal `check_importance(sentence)` tool.\n",
        "2. The tool's output is 'important' if the sentence is central to the main idea, otherwise it is 'not_important'.\n",
        "3. List the sentences that result in an 'important' output.\n",
        "4. If no sentences are important, return an empty list.\n",
        "5. Indices are 1-based.\n",
        "6. Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "x2jkAlJfThO0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**scoring-based prompting** instead gives a score to each sentence based on the relevance to the task. Also here we have the aspect-based version and the simple, importance-based one."
      ],
      "metadata": {
        "id": "8PUT3Ct-TkaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scoring_based_prompt(sentences, target_label):\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select sentences that express the \"{target_label}\" aspect of the document.\n",
        "\n",
        "Aspect definitions:\n",
        "- challenge: problem, gap, limitation, unmet need, difficulty/motivation.\n",
        "- approach: method, model, system, algorithm, dataset design, procedure.\n",
        "- outcome: results, findings, improvements, metrics, performance, impact.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "Instructions:\n",
        "1. For each sentence, assign a score from 1 (low relevance) to 5 (high relevance) for how well it expresses the \"{target_label}\" aspect.\n",
        "2. Only select sentences with a score of 4 or 5.\n",
        "3. If no sentences meet the threshold, return an empty list.\n",
        "4. Indices are 1-based.\n",
        "5. Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "8RKC2tnPTkuC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scoring_based_simple_prompt(sentences):\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select the most important sentences from the document.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "Instructions:\n",
        "1. For each sentence, assign a score from 1 (low importance) to 5 (high importance) for how central it is to the document's main idea.\n",
        "2. Only select sentences with a score of 4 or 5.\n",
        "3. If no sentences meet the threshold, return an empty list.\n",
        "4. Indices are 1-based.\n",
        "5. Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "-1yOAdzdT2ix"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**self-ask prompting** involves the model reasoning through a series of yes-no questions and using the answers to reach a conclustion."
      ],
      "metadata": {
        "id": "SNfKCbKsT5Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def self_ask_prompt(sentences, target_label):\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select sentences that express the \"{target_label}\" aspect of the document.\n",
        "\n",
        "Aspect definitions:\n",
        "- challenge: problem, gap, limitation, unmet need, difficulty/motivation.\n",
        "- approach: method, model, system, algorithm, dataset design, procedure.\n",
        "- outcome: results, findings, improvements, metrics, performance, impact.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "Instructions:\n",
        "1. Reason step-by-step. For each sentence, ask the question: \"Does this sentence primarily express the \"{target_label}\" aspect?\"\n",
        "2. Answer the question with \"Yes\" or \"No\".\n",
        "3. Compile a list of all sentences for which the answer was \"Yes\".\n",
        "4. If no sentences meet the criteria, return an empty list.\n",
        "5. Indices are 1-based.\n",
        "6. Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "RwLsmJpDT4-p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def self_ask_simple_prompt(sentences):\n",
        "    numbered = [f\"Sentence {i+1}: {s}\" for i, s in enumerate(sentences)]\n",
        "    input_text = \"\\n\".join(numbered)\n",
        "\n",
        "    return f'''You are an expert in extractive summarization. Your task is to select the most important sentences from the document.\n",
        "\n",
        "Input:\n",
        "{input_text}\n",
        "\n",
        "Instructions:\n",
        "1. Reason step-by-step. First, ask the question: \"What is the main idea of this document?\"\n",
        "2. Then, for each sentence, ask: \"Does this sentence support the main idea?\"\n",
        "3. Compile a list of all sentences for which the answer was \"Yes\".\n",
        "4. If no sentences are important, return an empty list.\n",
        "5. Indices are 1-based.\n",
        "6. Return ONLY valid JSON.\n",
        "\n",
        "Return format:\n",
        "{{\"selected_sentences\": [list_of_sentence_numbers]}}'''"
      ],
      "metadata": {
        "id": "WwKcjbjqUGH6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Transform gold standard to match output for each label:\n",
        "\n",
        "  so for example if the challenge_labels looks like this:\n",
        "\n",
        "  `[1,0,0,1,1,0]`\n",
        "\n",
        "  it will become\n",
        "\n",
        "  `[1, 4, 5]`\n",
        "\n"
      ],
      "metadata": {
        "id": "yrpaSqm3GR2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aspects to analyze\n",
        "ASPECTS = [\"challenge\", \"approach\", \"outcome\"]\n",
        "\n",
        "def labels_to_indices(labels):\n",
        "    \"\"\"0/1 list -> 1-based indices of 1s\"\"\"\n",
        "    return [i+1 for i, v in enumerate(labels) if int(v) == 1]\n",
        "\n",
        "def gold_for_doc(example):\n",
        "    \"\"\"\n",
        "    Build gold indices per aspect for ONE document.\n",
        "    Returns: {\"challenge\":[...], \"approach\":[...], \"outcome\":[...]}\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"challenge\": labels_to_indices(example[\"challenge_labels\"]),\n",
        "        \"approach\":  labels_to_indices(example[\"approach_labels\"]),\n",
        "        \"outcome\":   labels_to_indices(example[\"outcome_labels\"]),\n",
        "    }\n",
        "\n",
        "def gold_for_dataset(ds):\n",
        "    \"\"\"\n",
        "    Build gold indices per aspect for ALL docs.\n",
        "    Returns a list aligned with ds, where item i is gold_for_doc(ds[i])\n",
        "    \"\"\"\n",
        "    return [gold_for_doc(ex) for ex in ds]\n",
        "\n",
        "gold_all = gold_for_dataset(dataset)\n",
        "print(gold_all[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn-GJdXDAm6C",
        "outputId": "b88dcc5a-dcc4-411e-fc0e-f73354e5f69e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'challenge': [1, 2, 7, 11], 'approach': [3, 15, 19, 26, 27], 'outcome': [4, 5, 20, 21, 30, 31]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "u7eLPxSj4bOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re\n",
        "from transformers import AutoTokenizer, pipeline"
      ],
      "metadata": {
        "id": "kTjzD3P-NacX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re\n",
        "\n",
        "def safe_extract_json_strict(text: str):\n",
        "    text = text.strip()\n",
        "\n",
        "    try:\n",
        "        js = json.loads(text)\n",
        "        if isinstance(js, dict) and \"selected_sentences\" in js:\n",
        "            return js\n",
        "        if isinstance(js, list):\n",
        "            return {\"selected_sentences\": js}\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    text_clean = re.sub(r\"^```[\\w-]*\\s*\\n\", \"\", text, flags=re.S)\n",
        "    text_clean = re.sub(r\"\\n```$\", \"\", text_clean, flags=re.S).strip()\n",
        "\n",
        "    objs = re.findall(r\"\\{[\\s\\S]*?\\}\", text_clean)\n",
        "    for s in reversed(objs):\n",
        "        try:\n",
        "            js = json.loads(s)\n",
        "            if isinstance(js, dict) and \"selected_sentences\" in js:\n",
        "                return js\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    m = re.search(r\"(?m)^\\s*\\[(?:\\s*\\d+\\s*(?:,\\s*\\d+\\s*)*)?\\]\\s*$\", text_clean)\n",
        "    if m:\n",
        "        try:\n",
        "            arr = json.loads(m.group(0))\n",
        "            return {\"selected_sentences\": arr}\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return {}\n"
      ],
      "metadata": {
        "id": "nkK0JccA9t_e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The qwen model is pretrained on chat-like inputs, and therefore the input we have needs to be translated as a chat as well, and needs a system role\n",
        "\n",
        "- llama does not use this in the same way as Qwen and the system instruction is typically baked into the user prompt or handled differently"
      ],
      "metadata": {
        "id": "Jdj1lpqjbh3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_indices_for_aspect_qwen(model, tokenizer, prompt_technique, sentences, target_label, max_new_tokens=256, show_raw=False):\n",
        "    # Build prompt and format as chat text\n",
        "    user_prompt = prompt_technique(sentences, target_label)\n",
        "    chat_text = tokenizer.apply_chat_template(\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in extractive summarization.\"},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=False\n",
        "    )\n",
        "\n",
        "    print(f'lenght= {len(tokenizer.encode(chat_text))}')\n",
        "\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Use the model's generate method directly for robust generation\n",
        "    inputs = tokenizer(chat_text, return_tensors='pt', padding=True)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,  # This is the only generation flag you need\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the generated tokens to a string\n",
        "    out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    if show_raw:\n",
        "        print(f\"\\n[RAW OUTPUT for {target_label}]\\n{out}\\n\")\n",
        "\n",
        "    # Use the robust JSON parser on the decoded string\n",
        "    js = safe_extract_json_strict(out)\n",
        "    idxs = js.get(\"selected_sentences\", [])\n",
        "\n",
        "    # Sanitize indices\n",
        "    n = len(sentences)\n",
        "    cleaned = []\n",
        "    for v in idxs:\n",
        "        if isinstance(v, (int, float)):\n",
        "            v = int(v)\n",
        "            if 1 <= v <= n:\n",
        "                cleaned.append(v)\n",
        "    return sorted(set(cleaned))\n",
        "\n"
      ],
      "metadata": {
        "id": "gy_HikkzAm1i"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # def predict_indices_for_aspect_llama(prompt_technique, sentences, target_label, max_new_tokens=256, show_raw=False):\n",
        "  #   # Get the user prompt\n",
        "  #   user_prompt = prompt_technique(sentences, target_label)\n",
        "\n",
        "  #   chat_text = tokenizer.apply_chat_template(\n",
        "  #       [{\"role\": \"user\", \"content\": user_prompt}],\n",
        "  #       chat_template=\"{% for message in messages %}{% if message['role'] == 'user' %}[INST] {{ message['content'] }} [/INST]{% endif %}{% endfor %}\",\n",
        "  #       tokenize=False,\n",
        "  #       add_generation_prompt=True,\n",
        "  #   )\n",
        "\n",
        "  #   if tokenizer.pad_token_id is None:\n",
        "  #       tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "  #   # Use the model's generate method directly\n",
        "  #   inputs = tokenizer(chat_text, return_tensors='pt', padding=True)\n",
        "  #   inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "  #   outputs = model.generate(\n",
        "  #       **inputs,\n",
        "  #       max_new_tokens=max_new_tokens,\n",
        "  #       do_sample=False,\n",
        "  #       eos_token_id=tokenizer.eos_token_id,\n",
        "  #       pad_token_id=tokenizer.pad_token_id\n",
        "  #   )\n",
        "\n",
        "  #   # Decode the generated tokens\n",
        "  #   out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  #   if show_raw:\n",
        "  #       print(f\"\\n[RAW OUTPUT for {target_label}]\\n{out}\\n\")\n",
        "\n",
        "  #   # Use the robust JSON parser\n",
        "  #   js = safe_extract_json_strict(out)\n",
        "  #   idxs = js.get(\"selected_sentences\", [])\n",
        "\n",
        "  #   # Sanitize indices\n",
        "  #   n = len(sentences)\n",
        "  #   cleaned = []\n",
        "  #   for v in idxs:\n",
        "  #       if isinstance(v, (int, float)):\n",
        "  #           v = int(v)\n",
        "  #           if 1 <= v <= n:\n",
        "  #               cleaned.append(v)\n",
        "  #   return sorted(set(cleaned))\n",
        "\n",
        "# The Llama 3 chat template with headers\n",
        "# This is a robust template that works for both single-turn and multi-turn conversations\n",
        "def predict_indices_for_aspect_llama(model, tokenizer, prompt_technique, sentences, target_label, max_new_tokens=256, show_raw=False):\n",
        "    # Get the user prompt\n",
        "    user_prompt = prompt_technique(sentences, target_label)\n",
        "\n",
        "    chat_text = tokenizer.apply_chat_template(\n",
        "        [{\"role\": \"user\", \"content\": user_prompt}],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )\n",
        "\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    inputs = tokenizer(chat_text, return_tensors='pt', padding=True)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the generated tokens\n",
        "    out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    if show_raw:\n",
        "        print(f\"\\n[RAW OUTPUT for {target_label}]\\n{out}\\n\")\n",
        "\n",
        "    # Use the robust JSON parser\n",
        "    js = safe_extract_json_strict(out)\n",
        "    idxs = js.get(\"selected_sentences\", [])\n",
        "\n",
        "    # Sanitize indices\n",
        "    n = len(sentences)\n",
        "    cleaned = []\n",
        "    for v in idxs:\n",
        "        if isinstance(v, (int, float)):\n",
        "            v = int(v)\n",
        "            if 1 <= v <= n:\n",
        "                cleaned.append(v)\n",
        "    return sorted(set(cleaned))"
      ],
      "metadata": {
        "id": "NnTKNCTR1FdI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(gold_for_doc, predicted_indices):\n",
        "\n",
        "    # Convert lists to sets for efficient intersection and difference operations\n",
        "    gold_set = set(gold_for_doc)\n",
        "    predicted_set = set(predicted_indices)\n",
        "\n",
        "    # Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
        "    true_positives = len(gold_set.intersection(predicted_set))\n",
        "    false_positives = len(predicted_set.difference(gold_set))\n",
        "    false_negatives = len(gold_set.difference(predicted_set))\n",
        "\n",
        "    # Calculate Precision\n",
        "    if true_positives + false_positives == 0:\n",
        "        precision = 0.0\n",
        "    else:\n",
        "        precision = true_positives / (true_positives + false_positives)\n",
        "\n",
        "    # Calculate Recall\n",
        "    if true_positives + false_negatives == 0:\n",
        "        recall = 0.0\n",
        "    else:\n",
        "        recall = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "    # Calculate F1-score\n",
        "    if precision + recall == 0:\n",
        "        f1_score = 0.0\n",
        "    else:\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score\n",
        "    }"
      ],
      "metadata": {
        "id": "SyHTfBeV6KzD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation loop:\n",
        "\n",
        "The following function evaluates precision, recall and f1 for each aspect both for a single document and in an aggregate way"
      ],
      "metadata": {
        "id": "knIZFHvmQ28g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def run_evaluation(dataset, model_name, model, tokenizer, prompt_technique, gold_all, aspects, start=0, stop=None):\n",
        "#     if stop is None:\n",
        "#         stop = len(dataset)\n",
        "#     stop = min(stop, len(dataset))\n",
        "\n",
        "#     # Dictionaries to store metrics for macro-averaging\n",
        "#     all_metrics = {aspect: {\"precision\": [], \"recall\": [], \"f1_score\": []} for aspect in aspects}\n",
        "\n",
        "#     for doc_idx in range(start, stop):\n",
        "#         ex = dataset[doc_idx]\n",
        "#         sentences = ex[\"source_sentences\"]\n",
        "#         gold_standard = gold_all[doc_idx] # given that gold_all = gold_for_dataset(dataset)\n",
        "\n",
        "#         print(\"=\"*80)\n",
        "#         print(f\"Doc {doc_idx} (id={ex.get('id', 'NA')}) | #sentences={len(sentences)}\")\n",
        "#         print(\"-\"*80)\n",
        "\n",
        "#         for aspect in aspects:\n",
        "#             # get predicted indices for the current aspect\n",
        "#             if \"Qwen\" in model_name:\n",
        "#               print(\"Using Qwen\")\n",
        "#               predicted_indices = predict_indices_for_aspect_qwen(\n",
        "#                   model = model,\n",
        "#                   tokenizer = tokenizer,\n",
        "#                   prompt_technique=prompt_technique,\n",
        "#                   sentences=sentences,\n",
        "#                   target_label=aspect,\n",
        "#               )\n",
        "#             elif \"Llama\" in model_name:\n",
        "#               print(\"Using Llama\")\n",
        "#               predicted_indices = predict_indices_for_aspect_llama(\n",
        "#                   model = model,\n",
        "#                   tokenizer = tokenizer,\n",
        "#                   prompt_technique=prompt_technique,\n",
        "#                   sentences=sentences,\n",
        "#                   target_label=aspect,\n",
        "#               )\n",
        "\n",
        "#             # get gold standard for each aspect\n",
        "#             gold_indices = gold_standard.get(aspect, [])\n",
        "\n",
        "#             # Calculate metrics\n",
        "#             metrics = calculate_metrics(gold_indices, predicted_indices)\n",
        "\n",
        "#             # Print per-document results\n",
        "#             print(f\"  -> {aspect.capitalize():9s}\")\n",
        "#             print(f\"     Predicted: {sorted(predicted_indices)}\")\n",
        "#             print(f\"     Gold:      {sorted(gold_indices)}\")\n",
        "#             print(f\"     Metrics: P={metrics['precision']:.2f}, R={metrics['recall']:.2f}, F1={metrics['f1_score']:.2f}\")\n",
        "#             print()\n",
        "\n",
        "#             # Store metrics for aggregation\n",
        "#             all_metrics[aspect][\"precision\"].append(metrics['precision'])\n",
        "#             all_metrics[aspect][\"recall\"].append(metrics['recall'])\n",
        "#             all_metrics[aspect][\"f1_score\"].append(metrics['f1_score'])\n",
        "\n",
        "#     # Clculate and print the final aggregate scores\n",
        "#     print(\"\\n\" + \"=\"*80)\n",
        "#     print(\"--- Final Aggregate Metrics ---\")\n",
        "#     print(\"=\"*80)\n",
        "\n",
        "#     for aspect in aspects:\n",
        "#         avg_p = sum(all_metrics[aspect][\"precision\"]) / len(all_metrics[aspect][\"precision\"]) if all_metrics[aspect][\"precision\"] else 0\n",
        "#         avg_r = sum(all_metrics[aspect][\"recall\"]) / len(all_metrics[aspect][\"recall\"]) if all_metrics[aspect][\"recall\"] else 0\n",
        "#         avg_f1 = sum(all_metrics[aspect][\"f1_score\"]) / len(all_metrics[aspect][\"f1_score\"]) if all_metrics[aspect][\"f1_score\"] else 0\n",
        "\n",
        "#         print(f\"  -> {aspect.capitalize()} Average:\")\n",
        "#         print(f\"     Precision: {avg_p:.2f}\")\n",
        "#         print(f\"     Recall:    {avg_r:.2f}\")\n",
        "#         print(f\"     F1-score:  {avg_f1:.2f}\")\n",
        "#         print()\n",
        "\n",
        "#     print(\"=\"*80)"
      ],
      "metadata": {
        "id": "vDD8Hos46Kvs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from rouge_score import rouge_scorer\n",
        "import numpy as np\n",
        "\n",
        "# load abstractive dataset for rouge calculation\n",
        "abs_ds = load_dataset(\"sobamchan/aclsum\", \"abstractive\")[\"test\"]\n",
        "ABS_ASPECTS = [\"challenge\", \"approach\", \"outcome\"]\n",
        "\n",
        "abs_by_id = {\n",
        "    ex[\"id\"]: {a: ex[a] for a in ABS_ASPECTS}   # each is a single sentence string\n",
        "    for ex in abs_ds\n",
        "}\n",
        "\n",
        "# concatenate indices to text for rouge calculation\n",
        "def indices_to_text(sentences, idxs_1b):\n",
        "    return \" \".join(sentences[i-1] for i in idxs_1b if 1 <= i <= len(sentences))\n",
        "\n",
        "\n",
        "def run_evaluation(dataset, model_name, model, tokenizer, prompt_technique, gold_all, aspects, start=0, stop=None):\n",
        "    if stop is None:\n",
        "        stop = len(dataset)\n",
        "    stop = min(stop, len(dataset))\n",
        "\n",
        "    # metrics\n",
        "    all_metrics = {a: {\"precision\": [], \"recall\": [], \"f1_score\": []} for a in aspects}\n",
        "\n",
        "    # collect ROUGE per aspect\n",
        "    rouge_sc = rouge_scorer.RougeScorer([\"rouge1\",\"rouge2\",\"rougeL\"], use_stemmer=True)\n",
        "    rouge_logs = {a: {\"r1\": [], \"r2\": [], \"rL\": []} for a in aspects}\n",
        "\n",
        "    for doc_idx in range(start, stop):\n",
        "        ex = dataset[doc_idx]\n",
        "        doc_id = ex[\"id\"]\n",
        "        sentences = ex[\"source_sentences\"]\n",
        "        gold_standard = gold_all[doc_idx]\n",
        "\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Doc {doc_idx} (id={doc_id}) | #sentences={len(sentences)}\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        # get abstractive refs (skip ROUGE if not found for some reason)\n",
        "        abs_ref = abs_by_id.get(doc_id, None)\n",
        "\n",
        "        for aspect in aspects:\n",
        "            # perform actual predictions wither with Qwen or Llama\n",
        "            if \"Qwen\" in model_name:\n",
        "                predicted_indices = predict_indices_for_aspect_qwen(\n",
        "                    model=model, tokenizer=tokenizer,\n",
        "                    prompt_technique=prompt_technique,\n",
        "                    sentences=sentences, target_label=aspect,\n",
        "                )\n",
        "            elif \"Llama\" in model_name or \"LLaMA\" in model_name:\n",
        "                predicted_indices = predict_indices_for_aspect_llama(\n",
        "                    model=model, tokenizer=tokenizer,\n",
        "                    prompt_technique=prompt_technique,\n",
        "                    sentences=sentences, target_label=aspect,\n",
        "                )\n",
        "            else:\n",
        "                predicted_indices = []\n",
        "\n",
        "            # calculate metrics\n",
        "            gold_indices = gold_standard.get(aspect, [])\n",
        "            metrics = calculate_metrics(gold_indices, predicted_indices)\n",
        "            print(f\"  -> {aspect.capitalize():9s}\")\n",
        "            print(f\"     Predicted: {sorted(predicted_indices)}\")\n",
        "            print(f\"     Gold:      {sorted(gold_indices)}\")\n",
        "            print(f\"     Metrics: P={metrics['precision']:.2f}, R={metrics['recall']:.2f}, F1={metrics['f1_score']:.2f}\")\n",
        "\n",
        "            all_metrics[aspect][\"precision\"].append(metrics['precision'])\n",
        "            all_metrics[aspect][\"recall\"].append(metrics['recall'])\n",
        "            all_metrics[aspect][\"f1_score\"].append(metrics['f1_score'])\n",
        "\n",
        "            # Rouge calculation - compared to abstractive dataset\n",
        "            if abs_ref and abs_ref.get(aspect):\n",
        "                hyp = indices_to_text(sentences, predicted_indices)  # model’s extractive output (concatenated)\n",
        "                ref = abs_ref[aspect]                               # single-sentence human abstractive ref\n",
        "                rs = rouge_sc.score(ref, hyp)\n",
        "                rouge_logs[aspect][\"r1\"].append(rs[\"rouge1\"].fmeasure)\n",
        "                rouge_logs[aspect][\"r2\"].append(rs[\"rouge2\"].fmeasure)\n",
        "                rouge_logs[aspect][\"rL\"].append(rs[\"rougeL\"].fmeasure)\n",
        "                print(f\"     ROUGE F1: R1={rs['rouge1'].fmeasure:.3f}  R2={rs['rouge2'].fmeasure:.3f}  RL={rs['rougeL'].fmeasure:.3f}\")\n",
        "            else:\n",
        "                print(\"     ROUGE: (no abstractive reference found for this id/aspect)\")\n",
        "            print()\n",
        "\n",
        "    # Aggregate results\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"--- Final Aggregate Metrics ---\")\n",
        "    print(\"=\"*80)\n",
        "    for aspect in aspects:\n",
        "        P = all_metrics[aspect][\"precision\"]; R = all_metrics[aspect][\"recall\"]; F = all_metrics[aspect][\"f1_score\"]\n",
        "        avg_p = sum(P)/len(P) if P else 0.0\n",
        "        avg_r = sum(R)/len(R) if R else 0.0\n",
        "        avg_f = sum(F)/len(F) if F else 0.0\n",
        "\n",
        "        # ROUGE means\n",
        "        r1 = np.mean(rouge_logs[aspect][\"r1\"]) if rouge_logs[aspect][\"r1\"] else 0.0\n",
        "        r2 = np.mean(rouge_logs[aspect][\"r2\"]) if rouge_logs[aspect][\"r2\"] else 0.0\n",
        "        rL = np.mean(rouge_logs[aspect][\"rL\"]) if rouge_logs[aspect][\"rL\"] else 0.0\n",
        "\n",
        "        print(f\"  -> {aspect.capitalize()} Average:\")\n",
        "        print(f\"     Precision: {avg_p:.3f}   Recall: {avg_r:.3f}   F1: {avg_f:.3f}\")\n",
        "        print(f\"     ROUGE F1 : R1={r1:.3f}   R2={r2:.3f}   RL={rL:.3f}\\n\")\n",
        "    print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "1kOBgrvr3GFB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama Results"
      ],
      "metadata": {
        "id": "ci1R6NVdTsiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-3.2-3B-Instruct\" # Or \"meta-llama/Llama-3.2-3B-Instruct\" || Qwen/Qwen3-4B\n",
        "\n",
        "model, tokenizer = load_model_and_tokenizer(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "49ae054746654909aeb6fbc1d4f39bef",
            "ac2ba857b4f741cab477c98a39bc7c58",
            "e68ff1e449a14c0899afd54268f8b7ea",
            "35ea267b34474a04a797da9138631b8b",
            "283e91a050804e889ef718e21a43937d",
            "bd664fcd6cbe41a691b76766d60e0ad0",
            "da59ef4ccb6f417888d348565f5b4c66",
            "7d37f87b7f5b4d0abe4e7211c57870d9",
            "6af05782a7b34a08a876cd23bfe11368",
            "d6f0adbcd78b429f98bdd030c53fa897",
            "7f3be583f39a498897115875e67c7c20"
          ]
        },
        "id": "-b6ZG7JGV0uH",
        "outputId": "5f2f45b0-3437-429a-c924-dc11020b8da1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49ae054746654909aeb6fbc1d4f39bef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Llama model and tokenizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions for the first three documents for the **vanilla prompt**"
      ],
      "metadata": {
        "id": "QN_6b_XQa0fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_evaluation(dataset, model_name, model, tokenizer, vanilla_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXNS4E6e6Kty",
        "outputId": "3911e371-691f-4a4b-ad40-8c23960d01cd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 6, 7, 11, 14, 17, 19, 22, 23, 27, 29, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.13, R=0.75, F1=0.22\n",
            "     ROUGE F1: R1=0.069  R2=0.025  RL=0.057\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: []\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: []\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [9, 19, 28]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.33, R=0.33, F1=0.33\n",
            "     ROUGE F1: R1=0.306  R2=0.146  RL=0.122\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.29, R=1.00, F1=0.44\n",
            "     ROUGE F1: R1=0.063  R2=0.031  RL=0.055\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 21, 22, 26, 27]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=0.83, R=0.71, F1=0.77\n",
            "     ROUGE F1: R1=0.190  R2=0.077  RL=0.114\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 6, 15, 16]\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=0.50, R=0.67, F1=0.57\n",
            "     ROUGE F1: R1=0.225  R2=0.141  RL=0.193\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 11, 13, 14, 17]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.50, R=1.00, F1=0.67\n",
            "     ROUGE F1: R1=0.170  R2=0.129  RL=0.170\n",
            "\n",
            "  -> Outcome  \n",
            "     Predicted: [3, 4, 9, 10, 11, 12, 13, 14, 15, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.40, R=1.00, F1=0.57\n",
            "     ROUGE F1: R1=0.159  R2=0.051  RL=0.123\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.321   Recall: 0.583   F1: 0.376\n",
            "     ROUGE F1 : R1=0.200   R2=0.104   RL=0.124\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.262   Recall: 0.667   F1: 0.370\n",
            "     ROUGE F1 : R1=0.078   R2=0.053   RL=0.075\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.411   Recall: 0.571   F1: 0.447\n",
            "     ROUGE F1 : R1=0.116   R2=0.043   RL=0.079\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions for the first three documents for the **least to most prompt**"
      ],
      "metadata": {
        "id": "99H3fi5ja9Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# least_to_most_prompt\n",
        "run_evaluation(dataset, model_name, model, tokenizer, least_to_most_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "v-3GVhOW6Krz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ce2eb6-1fe0-4175-ca02-77112bfa468b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 6, 7, 11, 14, 17, 19, 22, 23, 27, 29, 37, 39, 41, 42, 43]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.19, R=0.75, F1=0.30\n",
            "     ROUGE F1: R1=0.102  R2=0.030  RL=0.066\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [3, 9, 12, 16, 17, 18, 19, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.11, R=0.60, F1=0.18\n",
            "     ROUGE F1: R1=0.048  R2=0.013  RL=0.036\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [4, 5, 6, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.16, R=1.00, F1=0.28\n",
            "     ROUGE F1: R1=0.053  R2=0.028  RL=0.043\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 9, 11, 19, 23, 27, 28]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.29, R=0.67, F1=0.40\n",
            "     ROUGE F1: R1=0.133  R2=0.063  RL=0.071\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.26, R=1.00, F1=0.41\n",
            "     ROUGE F1: R1=0.056  R2=0.028  RL=0.049\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 21, 22, 26, 27]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=0.83, R=0.71, F1=0.77\n",
            "     ROUGE F1: R1=0.190  R2=0.077  RL=0.114\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: []\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: []\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n",
            "  -> Outcome  \n",
            "     Predicted: []\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.158   Recall: 0.472   F1: 0.233\n",
            "     ROUGE F1 : R1=0.078   R2=0.031   RL=0.046\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.122   Recall: 0.533   F1: 0.197\n",
            "     ROUGE F1 : R1=0.035   R2=0.014   RL=0.028\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.332   Recall: 0.571   F1: 0.349\n",
            "     ROUGE F1 : R1=0.081   R2=0.035   RL=0.052\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions for the first three documents for the **tool augmented prompt**"
      ],
      "metadata": {
        "id": "__ChOx19b0b0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tool_augmented_prompt\n",
        "run_evaluation(dataset, model_name, model, tokenizer, tool_augmented_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "7L9dUV886Kpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2a8823-a17f-439c-8da6-a0bdaa6793b8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: []\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.11, R=1.00, F1=0.20\n",
            "     ROUGE F1: R1=0.032  R2=0.009  RL=0.026\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: []\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 9, 12, 19, 23, 27, 28, 29, 31, 32]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.20, R=0.67, F1=0.31\n",
            "     ROUGE F1: R1=0.135  R2=0.063  RL=0.072\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: []\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 21, 22, 26]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=1.00, R=0.71, F1=0.83\n",
            "     ROUGE F1: R1=0.229  R2=0.092  RL=0.137\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: []\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=0.00, R=0.00, F1=0.00\n",
            "     ROUGE F1: R1=0.000  R2=0.000  RL=0.000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 9, 11, 12, 13, 14, 15, 17]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.33, R=1.00, F1=0.50\n",
            "     ROUGE F1: R1=0.128  R2=0.096  RL=0.128\n",
            "\n",
            "  -> Outcome  \n",
            "     Predicted: [3, 4, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.36, R=1.00, F1=0.53\n",
            "     ROUGE F1: R1=0.142  R2=0.043  RL=0.105\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.067   Recall: 0.222   F1: 0.103\n",
            "     ROUGE F1 : R1=0.045   R2=0.021   RL=0.024\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.149   Recall: 0.667   F1: 0.235\n",
            "     ROUGE F1 : R1=0.053   R2=0.035   RL=0.051\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.455   Recall: 0.571   F1: 0.456\n",
            "     ROUGE F1 : R1=0.124   R2=0.045   RL=0.081\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions for the first three documents for the **scoring based prompt**"
      ],
      "metadata": {
        "id": "_77j3xIbb-VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scoring_based_prompt\n",
        "run_evaluation(dataset, model_name, model, tokenizer, scoring_based_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "U8c68dMC6Knr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9329bad3-19f2-4eab-9d7b-2d8b0ba33ae4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [2, 7, 11, 14, 17, 19, 22, 23, 27, 37, 39, 41, 42, 43]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.21, R=0.75, F1=0.33\n",
            "     ROUGE F1: R1=0.107  R2=0.040  RL=0.087\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [3, 9, 12, 16, 17, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.11, R=0.60, F1=0.18\n",
            "     ROUGE F1: R1=0.050  R2=0.013  RL=0.037\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [3, 4, 5, 6, 9, 10, 12, 14, 16, 17, 18, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44]\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.18, R=1.00, F1=0.31\n",
            "     ROUGE F1: R1=0.063  R2=0.030  RL=0.051\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 9, 11, 19, 21, 22, 23, 27, 28]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.22, R=0.67, F1=0.33\n",
            "     ROUGE F1: R1=0.099  R2=0.047  RL=0.053\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.26, R=1.00, F1=0.41\n",
            "     ROUGE F1: R1=0.056  R2=0.028  RL=0.049\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 11, 15, 16, 17, 20, 21, 22, 24, 26, 27, 31]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=0.46, R=0.86, F1=0.60\n",
            "     ROUGE F1: R1=0.097  R2=0.044  RL=0.078\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 6, 7, 8, 12, 13, 14, 16]\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=0.25, R=0.67, F1=0.36\n",
            "     ROUGE F1: R1=0.117  R2=0.077  RL=0.096\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 11, 13, 14]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.183  R2=0.139  RL=0.183\n",
            "\n",
            "  -> Outcome  \n",
            "     Predicted: [9, 10, 12, 13, 14, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.33, R=0.50, F1=0.40\n",
            "     ROUGE F1: R1=0.203  R2=0.059  RL=0.164\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.229   Recall: 0.694   F1: 0.343\n",
            "     ROUGE F1 : R1=0.108   R2=0.054   RL=0.079\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.322   Recall: 0.867   F1: 0.447\n",
            "     ROUGE F1 : R1=0.096   R2=0.060   RL=0.090\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.326   Recall: 0.786   F1: 0.436\n",
            "     ROUGE F1 : R1=0.121   R2=0.044   RL=0.098\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions for the first three documents for the **self ask prompt**"
      ],
      "metadata": {
        "id": "GBcnAjVFcNA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# self_ask_prompt\n",
        "run_evaluation(dataset, model_name, model, tokenizer, self_ask_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "WAc7OReR6KlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f2bebf-0e22-47cc-a415-1925fdb4cfa3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 6, 7, 11, 14, 17, 19, 22, 23, 27, 29, 31, 32, 37, 39, 41, 42, 43, 44]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.16, R=0.75, F1=0.26\n",
            "     ROUGE F1: R1=0.085  R2=0.030  RL=0.055\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.12, R=1.00, F1=0.21\n",
            "     ROUGE F1: R1=0.033  R2=0.009  RL=0.026\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [4, 5, 6, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.16, R=1.00, F1=0.28\n",
            "     ROUGE F1: R1=0.053  R2=0.028  RL=0.043\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 9, 12, 19, 23, 28]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.33, R=0.67, F1=0.44\n",
            "     ROUGE F1: R1=0.190  R2=0.090  RL=0.101\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.26, R=1.00, F1=0.41\n",
            "     ROUGE F1: R1=0.056  R2=0.028  RL=0.049\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 21, 22, 26, 27]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=0.83, R=0.71, F1=0.77\n",
            "     ROUGE F1: R1=0.190  R2=0.077  RL=0.114\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 6, 16]\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=0.67, R=0.67, F1=0.67\n",
            "     ROUGE F1: R1=0.243  R2=0.152  RL=0.208\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 11, 13, 14, 17]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.50, R=1.00, F1=0.67\n",
            "     ROUGE F1: R1=0.170  R2=0.129  RL=0.170\n",
            "\n",
            "  -> Outcome  \n",
            "     Predicted: [3, 4, 9, 10, 11, 12, 13, 14, 15, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.40, R=1.00, F1=0.57\n",
            "     ROUGE F1: R1=0.159  R2=0.051  RL=0.123\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.386   Recall: 0.694   F1: 0.457\n",
            "     ROUGE F1 : R1=0.173   R2=0.091   RL=0.122\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.291   Recall: 1.000   F1: 0.428\n",
            "     ROUGE F1 : R1=0.086   R2=0.055   RL=0.082\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.465   Recall: 0.905   F1: 0.540\n",
            "     ROUGE F1 : R1=0.134   R2=0.052   RL=0.093\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qwen results"
      ],
      "metadata": {
        "id": "R6DOFWpiVTy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Qwen/Qwen3-4B\" # Or \"meta-llama/Llama-3.2-3B-Instruct\" || Qwen/Qwen3-4B\n",
        "\n",
        "model, tokenizer = load_model_and_tokenizer(model_name)"
      ],
      "metadata": {
        "id": "B4ALWnaR6Kgt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436,
          "referenced_widgets": [
            "e91591571a5f4e2dbf6a4e9c763bc45b",
            "b629c94e42fd438491631ed64dc65979",
            "8b5d5b13c5794077af5fd6d4d8c64b19",
            "7fede0ec988a4a5ca9439fc06af889bc",
            "484bdf74280a4ddf86cdb4620b1e75bf",
            "3c350ffb9655493f8ee0314cac0bebca",
            "0fa37c2c0d7647a49933ef91877588e7",
            "539eb52d50914de59a1f31c714317120",
            "4f2aefffa65c4b568020deb6d4228fb5",
            "bf5d8650382c4efc96cc9de2019f6f2d",
            "d66ff94777d244dbbcb64928f1970969",
            "52f233aa316b499e854aa1340783e88e",
            "172917513d424c168923a00c3c632956",
            "410f9d207b0046cca246da4c3832c681",
            "9caf452ff4f74d22b34a331cc5dc88d4",
            "827fcd1d75bc4e2aaac1c83d21083e29",
            "da19da1f1a69418f8cd7820058cf7fb1",
            "5c880684c7b64e259ef6844e24fffd6d",
            "843c1399c4e14b25909d5c0c03102245",
            "a155cd0dbbc742b3b00121ba239559ea",
            "ad546b5338ce422892d0dbe79b6a292b",
            "adb157182d0f42a6a491b5aaec620ac3",
            "7949f6151c4743038e1b4c1711ae4bca",
            "c154f70012dc45659bc72c6919f517ab",
            "5e6241d7634c407d9887a30abc72b07e",
            "693ad9e11a704a4cb90baedd1a867eed",
            "16a1c157bcf9464c9c26b87cb3b31192",
            "1cef782f916f4283aa6c7957251af9d3",
            "46aaf39fb4c640a3aa583fbb08292424",
            "0b08128e6da7469288389bbf1ce26150",
            "f4e05fc543b94a8c8034e1da052e5bbb",
            "e6d4dd7ae0cc4234b82342229e287281",
            "26152553a8154be8b0a85b8d78e7141e",
            "ec00da6a7bc342dba52e84aea534a113",
            "4f8ec4833d894dfea7b94def79eb8b89",
            "856f556a6c9b4cdda70f714071ff9285",
            "62654ac2b8cc42208f23f509bcfb294e",
            "1e980bb17f2946fcaf5f6497302c68d7",
            "aff32ae2d616446dbe3ee62f1172ee39",
            "39b008fc828d41f4bbd177b4525a36c6",
            "01511692d70b4caf8de2fd0e1b95d3be",
            "782eab08dc1340e3b959771d543bf8cb",
            "04eddfba38264c1098e605c802e6fc6a",
            "3f9839c0c55841559bb554dcf02c7374",
            "138f89cedb0b4d5f8f039dcd313a98ad",
            "c9dde9daac7347bea22b09447f7ada6e",
            "3e29d6fbfe17413ba94f8ead4a826b2b",
            "748f9654c49543129105e00283956cd8",
            "7619ae029d344d18bbb10d0166557836",
            "c921be0c7a3449549c36d9a78ee682a6",
            "429b0df56cd944c1961f3714edcc96a9",
            "121d5162f36e4171a9756c7aff7d28a2",
            "ee759074c10041d0a3af7e72d5229cc1",
            "3ca6c91d756945fd8d014acecca496c2",
            "891da541aeed4f3ab6965e7dd7b6b551",
            "bf8f3636797643869b9e5995b6914db5",
            "5a30d6cb9b6c42faac578322b24b51a7",
            "832802e22e5b482e93782d4450ef3b24",
            "29e9936a86db435a995601588f9d1931",
            "df96e65c6d884c8888ffe768cb89d57b",
            "e27d1665a5ff464390ac0e228aa46b7b",
            "f137ee42cfa54ee99b71c4cac696d4d5",
            "6e75cce2a4d64dc4833def799cc45be0",
            "628730b4c0274e8397fe0d3b62acc020",
            "9f49b906eb9141c59db7725a80519cc2",
            "f8fea6e91466442e93e58a56dbdebee8",
            "c1d9da7771444c9cb51951418435083b",
            "a53efc042cbc48d091b50cceaeddfe13",
            "99928b221501433ebdf905628e28a2d0",
            "93d32ce71a80412b993df8328f54261c",
            "612a4ca25b664346b337192a1fe4669f",
            "df4b6b4932f6468db45a39444eeff8b1",
            "eb6cde8a686d44a2bead31458c100a70",
            "f11d43b2ae7842c59ece41d0240f654c",
            "16b6d44c602641018537c54123729389",
            "5a6a51f6737d49918277ffed3ede09b3",
            "29af2998e11f47948bcdef7c32aa03a6",
            "c3455b717c4848beb84313d3abcd9265",
            "8dac24e75fd24affa07bdd8590476dba",
            "3bfe6b769ed44d00ab8cf7df4b3c6701",
            "bba8ab1d59fd4c05bfde59642dab0af5",
            "9adc4cb8f0444b8e95a560d59f324b6a",
            "1ca8306e3bd84da48df9cc3ee53fd19a",
            "1340c0377eba4aedb39d12b249a92ab6",
            "7af117a4c86045f4b40c517ec705c6ef",
            "7bb9e5f8aeb54d989992aa7361ff8460",
            "efaef35dbaee49c684544b84c5292297",
            "74d6d6dee6cb4b8eadd8e7d4349e2c97",
            "9a04f1d005894681ab8532a02078576e",
            "de458922e76140e38759576cc5405fd6",
            "43e288b24bb4404888675fcc773edd46",
            "d366899035eb4214944af696440581cd",
            "db9e13d4c5f4483bb7fa374ba9d81d13",
            "e5614671b8984418afac1798841b0344",
            "0bd96c57d9284e30b50eb6212fcab23f",
            "6c511894b1a846ec884b51e5f0ce488a",
            "3ffe1c558462450d8db5f9de5cd66c69",
            "5f5474e37d994c1f9359d0677ffff6e7",
            "f8bee483a94b4199be602f14c47e1d52",
            "b849b8cb352b47b4ab2db33ea363a962",
            "21fefcaa7d554ebc98efbfd88d69a8e6",
            "5d0b50fe34d5408e87b6d635999b7e5d",
            "cf90f4029f7349b2aa5a8d6457ced69a",
            "83d53bcefe594e9fa25c533965d529cd",
            "f8958785050a4338a1a857ab21edab32",
            "031265569a9642ea9bbafd6e76ab3f6b",
            "39fac9a7da0d4959a1dc68d0ad7aa795",
            "f99338d1953248439ffb92755b7de7d7",
            "28eb40701b3a4069a96eab35b4128d71",
            "ab5fa6249ebb43c58b25f81c9da62309",
            "0f83eccaeff2484d96177876d57a6361",
            "7f7b38082a9744df9f51bdc4b2c3344d",
            "fe1e2e3330b04e7ca5bd7c982534ec45",
            "6164c01e9a4341b78d59bfd0b4006cfc",
            "c2a7ad8f1c334d69bec34431f8792cee",
            "a7dd36d91e084ed4bdaa533ba170e1a3",
            "6ac2eff73b6f4d7195993cebf5423b3e",
            "99b9f51357944868b931aeaf497c65e7",
            "8c762ca5a1c848af970e6b010882bd8f",
            "dece7352384e48fc88e1a44f51cf0d23",
            "d65f5f038a534195812eb4de521ee172",
            "db860671b90b401bb7c03ea1ba7a7bac",
            "c37d2a8269184884bc4868d8dcd75743",
            "6956b64612d041b68213cc364235628d",
            "f73a1066cd6a4df9a5295cb10d5ef3ca",
            "133e1ad196a441c8a6dec4979b78c01e",
            "4b685e6fc3fe4932865b7795e1912c43",
            "750713f4dd25453e9eab1e965d896a1d",
            "e4d0a873c4db436bb2a30507bc2660f9",
            "bd0978563c534b4fb8ea21361b8931e0",
            "20617b20eaa94b1aa1678d003274ef11",
            "dda9cd1b76464cf5ba70a5cabdbc3437"
          ]
        },
        "outputId": "4ffc5e1a-013d-48d5-e04d-aaea7faddb56"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e91591571a5f4e2dbf6a4e9c763bc45b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52f233aa316b499e854aa1340783e88e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7949f6151c4743038e1b4c1711ae4bca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec00da6a7bc342dba52e84aea534a113"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "138f89cedb0b4d5f8f039dcd313a98ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf8f3636797643869b9e5995b6914db5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1d9da7771444c9cb51951418435083b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3455b717c4848beb84313d3abcd9265"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a04f1d005894681ab8532a02078576e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/99.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b849b8cb352b47b4ab2db33ea363a962"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f83eccaeff2484d96177876d57a6361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db860671b90b401bb7c03ea1ba7a7bac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Qwen model and tokenizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### results for **vanilla prompt**"
      ],
      "metadata": {
        "id": "aM_ddET0Wi87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_evaluation(dataset, model_name, model, tokenizer, vanilla_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "3OXSPrNb6Ken",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73cc32d-d80e-49af-ca29-f21f76a6be75"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [2, 6, 11, 13, 14, 37]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.33, R=0.50, F1=0.40\n",
            "     ROUGE F1: R1=0.225  R2=0.076  RL=0.163\n",
            "\n",
            "lenght= 1553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [3, 9, 19, 26, 27, 28, 29, 30, 32, 35, 36, 37, 40, 41, 42, 43]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.25, R=0.80, F1=0.38\n",
            "     ROUGE F1: R1=0.079  R2=0.017  RL=0.056\n",
            "\n",
            "lenght= 1551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [3, 5, 19, 20, 21, 30, 31, 32, 33, 34, 35, 39]\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.42, R=0.83, F1=0.56\n",
            "     ROUGE F1: R1=0.137  R2=0.062  RL=0.110\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 7, 9, 12, 13]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.197  R2=0.080  RL=0.118\n",
            "\n",
            "lenght= 1596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 10, 11, 14, 15, 17, 18, 24, 25, 26]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.67, R=1.00, F1=0.80\n",
            "     ROUGE F1: R1=0.123  R2=0.062  RL=0.102\n",
            "\n",
            "lenght= 1594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 20, 21, 22, 26]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=1.00, R=0.86, F1=0.92\n",
            "     ROUGE F1: R1=0.200  R2=0.081  RL=0.130\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 5, 6, 16]\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=0.75, R=1.00, F1=0.86\n",
            "     ROUGE F1: R1=0.217  R2=0.139  RL=0.177\n",
            "\n",
            "lenght= 984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 8, 12, 14]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.153  R2=0.110  RL=0.145\n",
            "\n",
            "lenght= 982\n",
            "  -> Outcome  \n",
            "     Predicted: [9, 12, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.33, R=0.25, F1=0.29\n",
            "     ROUGE F1: R1=0.283  R2=0.077  RL=0.264\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.561   Recall: 0.833   F1: 0.669\n",
            "     ROUGE F1 : R1=0.213   R2=0.098   RL=0.153\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.506   Recall: 0.933   F1: 0.644\n",
            "     ROUGE F1 : R1=0.118   R2=0.063   RL=0.101\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.583   Recall: 0.647   F1: 0.588\n",
            "     ROUGE F1 : R1=0.207   R2=0.073   RL=0.168\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### results for **least to most prompt**"
      ],
      "metadata": {
        "id": "215-7LKyWqhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_evaluation(dataset, model_name, model, tokenizer, least_to_most_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "VZLeWJJe6KcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65caaa51-03d7-46f8-9775-422078eb1f08"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [2, 6, 11, 13, 14, 37]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.33, R=0.50, F1=0.40\n",
            "     ROUGE F1: R1=0.225  R2=0.076  RL=0.163\n",
            "\n",
            "lenght= 1570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [3, 9, 19, 26, 27, 28, 29, 30, 32, 35]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.40, R=0.80, F1=0.53\n",
            "     ROUGE F1: R1=0.101  R2=0.017  RL=0.084\n",
            "\n",
            "lenght= 1568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [3, 5, 19, 20, 21, 30, 31, 32, 33, 34, 35, 39]\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.42, R=0.83, F1=0.56\n",
            "     ROUGE F1: R1=0.137  R2=0.062  RL=0.110\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 7, 9, 12, 13]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.197  R2=0.080  RL=0.118\n",
            "\n",
            "lenght= 1613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 10, 11, 14, 15, 17, 18, 24, 25, 26]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.67, R=1.00, F1=0.80\n",
            "     ROUGE F1: R1=0.123  R2=0.062  RL=0.102\n",
            "\n",
            "lenght= 1611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 20, 21, 22, 26]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=1.00, R=0.86, F1=0.92\n",
            "     ROUGE F1: R1=0.200  R2=0.081  RL=0.130\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 5, 6, 16]\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=0.75, R=1.00, F1=0.86\n",
            "     ROUGE F1: R1=0.217  R2=0.139  RL=0.177\n",
            "\n",
            "lenght= 1001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 8, 12, 14]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.153  R2=0.110  RL=0.145\n",
            "\n",
            "lenght= 999\n",
            "  -> Outcome  \n",
            "     Predicted: [9, 12, 13, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.50, R=0.50, F1=0.50\n",
            "     ROUGE F1: R1=0.341  R2=0.099  RL=0.276\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.561   Recall: 0.833   F1: 0.669\n",
            "     ROUGE F1 : R1=0.213   R2=0.098   RL=0.153\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.556   Recall: 0.933   F1: 0.694\n",
            "     ROUGE F1 : R1=0.126   R2=0.063   RL=0.111\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.639   Recall: 0.730   F1: 0.660\n",
            "     ROUGE F1 : R1=0.226   R2=0.081   RL=0.172\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### results for **tool augmented prompt**"
      ],
      "metadata": {
        "id": "VMeCqUiKWuXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_evaluation(dataset, model_name, model, tokenizer, tool_augmented_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "yEh5BLzU6KaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df22d297-f117-4261-f768-24d0344d164a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [2, 6, 11, 13, 14, 37]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.33, R=0.50, F1=0.40\n",
            "     ROUGE F1: R1=0.225  R2=0.076  RL=0.163\n",
            "\n",
            "lenght= 1602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [3, 9, 19, 26, 27, 28, 29, 30, 32, 35, 36, 37, 40, 41, 42, 43]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.25, R=0.80, F1=0.38\n",
            "     ROUGE F1: R1=0.079  R2=0.017  RL=0.056\n",
            "\n",
            "lenght= 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [3, 5, 30, 31, 32, 33, 34, 35, 39]\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.33, R=0.50, F1=0.40\n",
            "     ROUGE F1: R1=0.168  R2=0.063  RL=0.105\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 7, 9, 12, 13]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.197  R2=0.080  RL=0.118\n",
            "\n",
            "lenght= 1645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 10, 11, 14, 15, 17, 18, 24, 25, 26]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.67, R=1.00, F1=0.80\n",
            "     ROUGE F1: R1=0.123  R2=0.062  RL=0.102\n",
            "\n",
            "lenght= 1643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 20, 21, 22, 26]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=1.00, R=0.86, F1=0.92\n",
            "     ROUGE F1: R1=0.200  R2=0.081  RL=0.130\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 5, 6]\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=1.00, R=1.00, F1=1.00\n",
            "     ROUGE F1: R1=0.282  R2=0.182  RL=0.231\n",
            "\n",
            "lenght= 1033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 8, 12, 14]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.153  R2=0.110  RL=0.145\n",
            "\n",
            "lenght= 1031\n",
            "  -> Outcome  \n",
            "     Predicted: [9, 12, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.33, R=0.25, F1=0.29\n",
            "     ROUGE F1: R1=0.283  R2=0.077  RL=0.264\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.644   Recall: 0.833   F1: 0.717\n",
            "     ROUGE F1 : R1=0.235   R2=0.113   RL=0.171\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.506   Recall: 0.933   F1: 0.644\n",
            "     ROUGE F1 : R1=0.118   R2=0.063   RL=0.101\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.556   Recall: 0.536   F1: 0.536\n",
            "     ROUGE F1 : R1=0.217   R2=0.074   RL=0.166\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### results for **scoring based prompt**"
      ],
      "metadata": {
        "id": "E4jaXxavWxLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_evaluation(dataset, model_name, model, tokenizer, scoring_based_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "hUSw1lDG6KX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4832d3b7-0874-4526-f79e-3bd369ca825a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [2, 6, 11, 13, 14, 37]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.33, R=0.50, F1=0.40\n",
            "     ROUGE F1: R1=0.225  R2=0.076  RL=0.163\n",
            "\n",
            "lenght= 1595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [3, 9, 19, 26, 27, 28, 29, 30, 32, 35, 36, 37, 40, 41, 42, 43]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.25, R=0.80, F1=0.38\n",
            "     ROUGE F1: R1=0.079  R2=0.017  RL=0.056\n",
            "\n",
            "lenght= 1593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [3, 5, 19, 20, 21, 30, 31, 32, 33, 34, 35, 39]\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.42, R=0.83, F1=0.56\n",
            "     ROUGE F1: R1=0.137  R2=0.062  RL=0.110\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 7, 9, 13, 26]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.198  R2=0.075  RL=0.111\n",
            "\n",
            "lenght= 1638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 10, 11, 14, 15, 17, 18, 24, 25, 26]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.67, R=1.00, F1=0.80\n",
            "     ROUGE F1: R1=0.123  R2=0.062  RL=0.102\n",
            "\n",
            "lenght= 1636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 20, 21, 22, 26]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=1.00, R=0.86, F1=0.92\n",
            "     ROUGE F1: R1=0.200  R2=0.081  RL=0.130\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 5, 6, 7]\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=0.75, R=1.00, F1=0.86\n",
            "     ROUGE F1: R1=0.225  R2=0.149  RL=0.176\n",
            "\n",
            "lenght= 1026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 8, 12, 14]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.153  R2=0.110  RL=0.145\n",
            "\n",
            "lenght= 1024\n",
            "  -> Outcome  \n",
            "     Predicted: [9, 12, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.33, R=0.25, F1=0.29\n",
            "     ROUGE F1: R1=0.283  R2=0.077  RL=0.264\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.561   Recall: 0.833   F1: 0.669\n",
            "     ROUGE F1 : R1=0.216   R2=0.100   RL=0.150\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.506   Recall: 0.933   F1: 0.644\n",
            "     ROUGE F1 : R1=0.118   R2=0.063   RL=0.101\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.583   Recall: 0.647   F1: 0.588\n",
            "     ROUGE F1 : R1=0.207   R2=0.073   RL=0.168\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### results for **self ask prompt**"
      ],
      "metadata": {
        "id": "9iHRlUapW0Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_evaluation(dataset, model_name, model, tokenizer, self_ask_prompt, gold_all, ASPECTS, stop=3)"
      ],
      "metadata": {
        "id": "_P7j4GUf6KVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d236a978-fd07-4cd2-8549-aba328477d78"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Doc 0 (id=E09-1056) | #sentences=44\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [2, 6, 11, 13, 14, 37]\n",
            "     Gold:      [1, 2, 7, 11]\n",
            "     Metrics: P=0.33, R=0.50, F1=0.40\n",
            "     ROUGE F1: R1=0.225  R2=0.076  RL=0.163\n",
            "\n",
            "lenght= 1602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [3, 9, 19, 26, 27, 28, 29, 30, 32, 35, 36, 37, 40, 41, 42, 43]\n",
            "     Gold:      [3, 15, 19, 26, 27]\n",
            "     Metrics: P=0.25, R=0.80, F1=0.38\n",
            "     ROUGE F1: R1=0.079  R2=0.017  RL=0.056\n",
            "\n",
            "lenght= 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [3, 5, 30, 31, 32, 33, 34, 35, 39]\n",
            "     Gold:      [4, 5, 20, 21, 30, 31]\n",
            "     Metrics: P=0.33, R=0.50, F1=0.40\n",
            "     ROUGE F1: R1=0.168  R2=0.063  RL=0.105\n",
            "\n",
            "================================================================================\n",
            "Doc 1 (id=N19-1362) | #sentences=32\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 7, 9, 12, 13]\n",
            "     Gold:      [1, 7, 9]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.197  R2=0.080  RL=0.118\n",
            "\n",
            "lenght= 1645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 3, 4, 10, 11, 14, 15, 17, 18, 24, 25, 26]\n",
            "     Gold:      [2, 3, 10, 11, 14, 15, 24, 25]\n",
            "     Metrics: P=0.67, R=1.00, F1=0.80\n",
            "     ROUGE F1: R1=0.123  R2=0.062  RL=0.102\n",
            "\n",
            "lenght= 1643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Outcome  \n",
            "     Predicted: [5, 6, 20, 21, 22, 26]\n",
            "     Gold:      [5, 6, 13, 20, 21, 22, 26]\n",
            "     Metrics: P=1.00, R=0.86, F1=0.92\n",
            "     ROUGE F1: R1=0.200  R2=0.081  RL=0.130\n",
            "\n",
            "================================================================================\n",
            "Doc 2 (id=P01-1040) | #sentences=17\n",
            "--------------------------------------------------------------------------------\n",
            "lenght= 1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Challenge\n",
            "     Predicted: [1, 5, 6]\n",
            "     Gold:      [1, 5, 6]\n",
            "     Metrics: P=1.00, R=1.00, F1=1.00\n",
            "     ROUGE F1: R1=0.282  R2=0.182  RL=0.231\n",
            "\n",
            "lenght= 1033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Approach \n",
            "     Predicted: [2, 7, 8, 12, 14]\n",
            "     Gold:      [2, 7, 14]\n",
            "     Metrics: P=0.60, R=1.00, F1=0.75\n",
            "     ROUGE F1: R1=0.153  R2=0.110  RL=0.145\n",
            "\n",
            "lenght= 1031\n",
            "  -> Outcome  \n",
            "     Predicted: [9, 12, 17]\n",
            "     Gold:      [3, 4, 12, 13]\n",
            "     Metrics: P=0.33, R=0.25, F1=0.29\n",
            "     ROUGE F1: R1=0.283  R2=0.077  RL=0.264\n",
            "\n",
            "\n",
            "================================================================================\n",
            "--- Final Aggregate Metrics ---\n",
            "================================================================================\n",
            "  -> Challenge Average:\n",
            "     Precision: 0.644   Recall: 0.833   F1: 0.717\n",
            "     ROUGE F1 : R1=0.235   R2=0.113   RL=0.171\n",
            "\n",
            "  -> Approach Average:\n",
            "     Precision: 0.506   Recall: 0.933   F1: 0.644\n",
            "     ROUGE F1 : R1=0.118   R2=0.063   RL=0.101\n",
            "\n",
            "  -> Outcome Average:\n",
            "     Precision: 0.556   Recall: 0.536   F1: 0.536\n",
            "     ROUGE F1 : R1=0.217   R2=0.074   RL=0.166\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j1QmsYCcAmk3"
      },
      "execution_count": 44,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49ae054746654909aeb6fbc1d4f39bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac2ba857b4f741cab477c98a39bc7c58",
              "IPY_MODEL_e68ff1e449a14c0899afd54268f8b7ea",
              "IPY_MODEL_35ea267b34474a04a797da9138631b8b"
            ],
            "layout": "IPY_MODEL_283e91a050804e889ef718e21a43937d"
          }
        },
        "ac2ba857b4f741cab477c98a39bc7c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd664fcd6cbe41a691b76766d60e0ad0",
            "placeholder": "​",
            "style": "IPY_MODEL_da59ef4ccb6f417888d348565f5b4c66",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e68ff1e449a14c0899afd54268f8b7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d37f87b7f5b4d0abe4e7211c57870d9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6af05782a7b34a08a876cd23bfe11368",
            "value": 2
          }
        },
        "35ea267b34474a04a797da9138631b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6f0adbcd78b429f98bdd030c53fa897",
            "placeholder": "​",
            "style": "IPY_MODEL_7f3be583f39a498897115875e67c7c20",
            "value": " 2/2 [00:02&lt;00:00,  1.11it/s]"
          }
        },
        "283e91a050804e889ef718e21a43937d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd664fcd6cbe41a691b76766d60e0ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da59ef4ccb6f417888d348565f5b4c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d37f87b7f5b4d0abe4e7211c57870d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af05782a7b34a08a876cd23bfe11368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6f0adbcd78b429f98bdd030c53fa897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f3be583f39a498897115875e67c7c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e91591571a5f4e2dbf6a4e9c763bc45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b629c94e42fd438491631ed64dc65979",
              "IPY_MODEL_8b5d5b13c5794077af5fd6d4d8c64b19",
              "IPY_MODEL_7fede0ec988a4a5ca9439fc06af889bc"
            ],
            "layout": "IPY_MODEL_484bdf74280a4ddf86cdb4620b1e75bf"
          }
        },
        "b629c94e42fd438491631ed64dc65979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c350ffb9655493f8ee0314cac0bebca",
            "placeholder": "​",
            "style": "IPY_MODEL_0fa37c2c0d7647a49933ef91877588e7",
            "value": "tokenizer_config.json: "
          }
        },
        "8b5d5b13c5794077af5fd6d4d8c64b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_539eb52d50914de59a1f31c714317120",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f2aefffa65c4b568020deb6d4228fb5",
            "value": 1
          }
        },
        "7fede0ec988a4a5ca9439fc06af889bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf5d8650382c4efc96cc9de2019f6f2d",
            "placeholder": "​",
            "style": "IPY_MODEL_d66ff94777d244dbbcb64928f1970969",
            "value": " 9.73k/? [00:00&lt;00:00, 671kB/s]"
          }
        },
        "484bdf74280a4ddf86cdb4620b1e75bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c350ffb9655493f8ee0314cac0bebca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa37c2c0d7647a49933ef91877588e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "539eb52d50914de59a1f31c714317120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4f2aefffa65c4b568020deb6d4228fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf5d8650382c4efc96cc9de2019f6f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d66ff94777d244dbbcb64928f1970969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f233aa316b499e854aa1340783e88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_172917513d424c168923a00c3c632956",
              "IPY_MODEL_410f9d207b0046cca246da4c3832c681",
              "IPY_MODEL_9caf452ff4f74d22b34a331cc5dc88d4"
            ],
            "layout": "IPY_MODEL_827fcd1d75bc4e2aaac1c83d21083e29"
          }
        },
        "172917513d424c168923a00c3c632956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da19da1f1a69418f8cd7820058cf7fb1",
            "placeholder": "​",
            "style": "IPY_MODEL_5c880684c7b64e259ef6844e24fffd6d",
            "value": "vocab.json: "
          }
        },
        "410f9d207b0046cca246da4c3832c681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843c1399c4e14b25909d5c0c03102245",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a155cd0dbbc742b3b00121ba239559ea",
            "value": 1
          }
        },
        "9caf452ff4f74d22b34a331cc5dc88d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad546b5338ce422892d0dbe79b6a292b",
            "placeholder": "​",
            "style": "IPY_MODEL_adb157182d0f42a6a491b5aaec620ac3",
            "value": " 2.78M/? [00:00&lt;00:00, 96.2MB/s]"
          }
        },
        "827fcd1d75bc4e2aaac1c83d21083e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da19da1f1a69418f8cd7820058cf7fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c880684c7b64e259ef6844e24fffd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843c1399c4e14b25909d5c0c03102245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a155cd0dbbc742b3b00121ba239559ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad546b5338ce422892d0dbe79b6a292b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb157182d0f42a6a491b5aaec620ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7949f6151c4743038e1b4c1711ae4bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c154f70012dc45659bc72c6919f517ab",
              "IPY_MODEL_5e6241d7634c407d9887a30abc72b07e",
              "IPY_MODEL_693ad9e11a704a4cb90baedd1a867eed"
            ],
            "layout": "IPY_MODEL_16a1c157bcf9464c9c26b87cb3b31192"
          }
        },
        "c154f70012dc45659bc72c6919f517ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cef782f916f4283aa6c7957251af9d3",
            "placeholder": "​",
            "style": "IPY_MODEL_46aaf39fb4c640a3aa583fbb08292424",
            "value": "merges.txt: "
          }
        },
        "5e6241d7634c407d9887a30abc72b07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b08128e6da7469288389bbf1ce26150",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4e05fc543b94a8c8034e1da052e5bbb",
            "value": 1
          }
        },
        "693ad9e11a704a4cb90baedd1a867eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6d4dd7ae0cc4234b82342229e287281",
            "placeholder": "​",
            "style": "IPY_MODEL_26152553a8154be8b0a85b8d78e7141e",
            "value": " 1.67M/? [00:00&lt;00:00, 81.1MB/s]"
          }
        },
        "16a1c157bcf9464c9c26b87cb3b31192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cef782f916f4283aa6c7957251af9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46aaf39fb4c640a3aa583fbb08292424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b08128e6da7469288389bbf1ce26150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f4e05fc543b94a8c8034e1da052e5bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6d4dd7ae0cc4234b82342229e287281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26152553a8154be8b0a85b8d78e7141e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec00da6a7bc342dba52e84aea534a113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f8ec4833d894dfea7b94def79eb8b89",
              "IPY_MODEL_856f556a6c9b4cdda70f714071ff9285",
              "IPY_MODEL_62654ac2b8cc42208f23f509bcfb294e"
            ],
            "layout": "IPY_MODEL_1e980bb17f2946fcaf5f6497302c68d7"
          }
        },
        "4f8ec4833d894dfea7b94def79eb8b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff32ae2d616446dbe3ee62f1172ee39",
            "placeholder": "​",
            "style": "IPY_MODEL_39b008fc828d41f4bbd177b4525a36c6",
            "value": "tokenizer.json: 100%"
          }
        },
        "856f556a6c9b4cdda70f714071ff9285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01511692d70b4caf8de2fd0e1b95d3be",
            "max": 11422654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_782eab08dc1340e3b959771d543bf8cb",
            "value": 11422654
          }
        },
        "62654ac2b8cc42208f23f509bcfb294e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04eddfba38264c1098e605c802e6fc6a",
            "placeholder": "​",
            "style": "IPY_MODEL_3f9839c0c55841559bb554dcf02c7374",
            "value": " 11.4M/11.4M [00:01&lt;00:00, 2.46MB/s]"
          }
        },
        "1e980bb17f2946fcaf5f6497302c68d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff32ae2d616446dbe3ee62f1172ee39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b008fc828d41f4bbd177b4525a36c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01511692d70b4caf8de2fd0e1b95d3be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "782eab08dc1340e3b959771d543bf8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04eddfba38264c1098e605c802e6fc6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9839c0c55841559bb554dcf02c7374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "138f89cedb0b4d5f8f039dcd313a98ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9dde9daac7347bea22b09447f7ada6e",
              "IPY_MODEL_3e29d6fbfe17413ba94f8ead4a826b2b",
              "IPY_MODEL_748f9654c49543129105e00283956cd8"
            ],
            "layout": "IPY_MODEL_7619ae029d344d18bbb10d0166557836"
          }
        },
        "c9dde9daac7347bea22b09447f7ada6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c921be0c7a3449549c36d9a78ee682a6",
            "placeholder": "​",
            "style": "IPY_MODEL_429b0df56cd944c1961f3714edcc96a9",
            "value": "config.json: 100%"
          }
        },
        "3e29d6fbfe17413ba94f8ead4a826b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_121d5162f36e4171a9756c7aff7d28a2",
            "max": 726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee759074c10041d0a3af7e72d5229cc1",
            "value": 726
          }
        },
        "748f9654c49543129105e00283956cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca6c91d756945fd8d014acecca496c2",
            "placeholder": "​",
            "style": "IPY_MODEL_891da541aeed4f3ab6965e7dd7b6b551",
            "value": " 726/726 [00:00&lt;00:00, 86.9kB/s]"
          }
        },
        "7619ae029d344d18bbb10d0166557836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c921be0c7a3449549c36d9a78ee682a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429b0df56cd944c1961f3714edcc96a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "121d5162f36e4171a9756c7aff7d28a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee759074c10041d0a3af7e72d5229cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ca6c91d756945fd8d014acecca496c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "891da541aeed4f3ab6965e7dd7b6b551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf8f3636797643869b9e5995b6914db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a30d6cb9b6c42faac578322b24b51a7",
              "IPY_MODEL_832802e22e5b482e93782d4450ef3b24",
              "IPY_MODEL_29e9936a86db435a995601588f9d1931"
            ],
            "layout": "IPY_MODEL_df96e65c6d884c8888ffe768cb89d57b"
          }
        },
        "5a30d6cb9b6c42faac578322b24b51a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e27d1665a5ff464390ac0e228aa46b7b",
            "placeholder": "​",
            "style": "IPY_MODEL_f137ee42cfa54ee99b71c4cac696d4d5",
            "value": "model.safetensors.index.json: "
          }
        },
        "832802e22e5b482e93782d4450ef3b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e75cce2a4d64dc4833def799cc45be0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_628730b4c0274e8397fe0d3b62acc020",
            "value": 1
          }
        },
        "29e9936a86db435a995601588f9d1931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f49b906eb9141c59db7725a80519cc2",
            "placeholder": "​",
            "style": "IPY_MODEL_f8fea6e91466442e93e58a56dbdebee8",
            "value": " 32.8k/? [00:00&lt;00:00, 3.85MB/s]"
          }
        },
        "df96e65c6d884c8888ffe768cb89d57b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27d1665a5ff464390ac0e228aa46b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f137ee42cfa54ee99b71c4cac696d4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e75cce2a4d64dc4833def799cc45be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "628730b4c0274e8397fe0d3b62acc020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f49b906eb9141c59db7725a80519cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fea6e91466442e93e58a56dbdebee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d9da7771444c9cb51951418435083b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a53efc042cbc48d091b50cceaeddfe13",
              "IPY_MODEL_99928b221501433ebdf905628e28a2d0",
              "IPY_MODEL_93d32ce71a80412b993df8328f54261c"
            ],
            "layout": "IPY_MODEL_612a4ca25b664346b337192a1fe4669f"
          }
        },
        "a53efc042cbc48d091b50cceaeddfe13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df4b6b4932f6468db45a39444eeff8b1",
            "placeholder": "​",
            "style": "IPY_MODEL_eb6cde8a686d44a2bead31458c100a70",
            "value": "Fetching 3 files: 100%"
          }
        },
        "99928b221501433ebdf905628e28a2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f11d43b2ae7842c59ece41d0240f654c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16b6d44c602641018537c54123729389",
            "value": 3
          }
        },
        "93d32ce71a80412b993df8328f54261c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a6a51f6737d49918277ffed3ede09b3",
            "placeholder": "​",
            "style": "IPY_MODEL_29af2998e11f47948bcdef7c32aa03a6",
            "value": " 3/3 [00:57&lt;00:00, 24.08s/it]"
          }
        },
        "612a4ca25b664346b337192a1fe4669f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4b6b4932f6468db45a39444eeff8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb6cde8a686d44a2bead31458c100a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f11d43b2ae7842c59ece41d0240f654c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b6d44c602641018537c54123729389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a6a51f6737d49918277ffed3ede09b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29af2998e11f47948bcdef7c32aa03a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3455b717c4848beb84313d3abcd9265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dac24e75fd24affa07bdd8590476dba",
              "IPY_MODEL_3bfe6b769ed44d00ab8cf7df4b3c6701",
              "IPY_MODEL_bba8ab1d59fd4c05bfde59642dab0af5"
            ],
            "layout": "IPY_MODEL_9adc4cb8f0444b8e95a560d59f324b6a"
          }
        },
        "8dac24e75fd24affa07bdd8590476dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ca8306e3bd84da48df9cc3ee53fd19a",
            "placeholder": "​",
            "style": "IPY_MODEL_1340c0377eba4aedb39d12b249a92ab6",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "3bfe6b769ed44d00ab8cf7df4b3c6701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7af117a4c86045f4b40c517ec705c6ef",
            "max": 3957900840,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bb9e5f8aeb54d989992aa7361ff8460",
            "value": 3957900840
          }
        },
        "bba8ab1d59fd4c05bfde59642dab0af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efaef35dbaee49c684544b84c5292297",
            "placeholder": "​",
            "style": "IPY_MODEL_74d6d6dee6cb4b8eadd8e7d4349e2c97",
            "value": " 3.96G/3.96G [00:54&lt;00:00, 95.2MB/s]"
          }
        },
        "9adc4cb8f0444b8e95a560d59f324b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ca8306e3bd84da48df9cc3ee53fd19a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1340c0377eba4aedb39d12b249a92ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7af117a4c86045f4b40c517ec705c6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb9e5f8aeb54d989992aa7361ff8460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efaef35dbaee49c684544b84c5292297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d6d6dee6cb4b8eadd8e7d4349e2c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a04f1d005894681ab8532a02078576e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de458922e76140e38759576cc5405fd6",
              "IPY_MODEL_43e288b24bb4404888675fcc773edd46",
              "IPY_MODEL_d366899035eb4214944af696440581cd"
            ],
            "layout": "IPY_MODEL_db9e13d4c5f4483bb7fa374ba9d81d13"
          }
        },
        "de458922e76140e38759576cc5405fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5614671b8984418afac1798841b0344",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd96c57d9284e30b50eb6212fcab23f",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "43e288b24bb4404888675fcc773edd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c511894b1a846ec884b51e5f0ce488a",
            "max": 3987450520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ffe1c558462450d8db5f9de5cd66c69",
            "value": 3987450520
          }
        },
        "d366899035eb4214944af696440581cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f5474e37d994c1f9359d0677ffff6e7",
            "placeholder": "​",
            "style": "IPY_MODEL_f8bee483a94b4199be602f14c47e1d52",
            "value": " 3.99G/3.99G [00:56&lt;00:00, 100MB/s]"
          }
        },
        "db9e13d4c5f4483bb7fa374ba9d81d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5614671b8984418afac1798841b0344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd96c57d9284e30b50eb6212fcab23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c511894b1a846ec884b51e5f0ce488a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffe1c558462450d8db5f9de5cd66c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f5474e37d994c1f9359d0677ffff6e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8bee483a94b4199be602f14c47e1d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b849b8cb352b47b4ab2db33ea363a962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21fefcaa7d554ebc98efbfd88d69a8e6",
              "IPY_MODEL_5d0b50fe34d5408e87b6d635999b7e5d",
              "IPY_MODEL_cf90f4029f7349b2aa5a8d6457ced69a"
            ],
            "layout": "IPY_MODEL_83d53bcefe594e9fa25c533965d529cd"
          }
        },
        "21fefcaa7d554ebc98efbfd88d69a8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8958785050a4338a1a857ab21edab32",
            "placeholder": "​",
            "style": "IPY_MODEL_031265569a9642ea9bbafd6e76ab3f6b",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "5d0b50fe34d5408e87b6d635999b7e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39fac9a7da0d4959a1dc68d0ad7aa795",
            "max": 99630640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f99338d1953248439ffb92755b7de7d7",
            "value": 99630640
          }
        },
        "cf90f4029f7349b2aa5a8d6457ced69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28eb40701b3a4069a96eab35b4128d71",
            "placeholder": "​",
            "style": "IPY_MODEL_ab5fa6249ebb43c58b25f81c9da62309",
            "value": " 99.6M/99.6M [00:01&lt;00:00, 66.6MB/s]"
          }
        },
        "83d53bcefe594e9fa25c533965d529cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8958785050a4338a1a857ab21edab32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031265569a9642ea9bbafd6e76ab3f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39fac9a7da0d4959a1dc68d0ad7aa795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99338d1953248439ffb92755b7de7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28eb40701b3a4069a96eab35b4128d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab5fa6249ebb43c58b25f81c9da62309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f83eccaeff2484d96177876d57a6361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f7b38082a9744df9f51bdc4b2c3344d",
              "IPY_MODEL_fe1e2e3330b04e7ca5bd7c982534ec45",
              "IPY_MODEL_6164c01e9a4341b78d59bfd0b4006cfc"
            ],
            "layout": "IPY_MODEL_c2a7ad8f1c334d69bec34431f8792cee"
          }
        },
        "7f7b38082a9744df9f51bdc4b2c3344d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7dd36d91e084ed4bdaa533ba170e1a3",
            "placeholder": "​",
            "style": "IPY_MODEL_6ac2eff73b6f4d7195993cebf5423b3e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fe1e2e3330b04e7ca5bd7c982534ec45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b9f51357944868b931aeaf497c65e7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c762ca5a1c848af970e6b010882bd8f",
            "value": 3
          }
        },
        "6164c01e9a4341b78d59bfd0b4006cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dece7352384e48fc88e1a44f51cf0d23",
            "placeholder": "​",
            "style": "IPY_MODEL_d65f5f038a534195812eb4de521ee172",
            "value": " 3/3 [00:05&lt;00:00,  2.39s/it]"
          }
        },
        "c2a7ad8f1c334d69bec34431f8792cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7dd36d91e084ed4bdaa533ba170e1a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac2eff73b6f4d7195993cebf5423b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99b9f51357944868b931aeaf497c65e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c762ca5a1c848af970e6b010882bd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dece7352384e48fc88e1a44f51cf0d23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d65f5f038a534195812eb4de521ee172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db860671b90b401bb7c03ea1ba7a7bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c37d2a8269184884bc4868d8dcd75743",
              "IPY_MODEL_6956b64612d041b68213cc364235628d",
              "IPY_MODEL_f73a1066cd6a4df9a5295cb10d5ef3ca"
            ],
            "layout": "IPY_MODEL_133e1ad196a441c8a6dec4979b78c01e"
          }
        },
        "c37d2a8269184884bc4868d8dcd75743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b685e6fc3fe4932865b7795e1912c43",
            "placeholder": "​",
            "style": "IPY_MODEL_750713f4dd25453e9eab1e965d896a1d",
            "value": "generation_config.json: 100%"
          }
        },
        "6956b64612d041b68213cc364235628d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d0a873c4db436bb2a30507bc2660f9",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd0978563c534b4fb8ea21361b8931e0",
            "value": 239
          }
        },
        "f73a1066cd6a4df9a5295cb10d5ef3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20617b20eaa94b1aa1678d003274ef11",
            "placeholder": "​",
            "style": "IPY_MODEL_dda9cd1b76464cf5ba70a5cabdbc3437",
            "value": " 239/239 [00:00&lt;00:00, 30.2kB/s]"
          }
        },
        "133e1ad196a441c8a6dec4979b78c01e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b685e6fc3fe4932865b7795e1912c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750713f4dd25453e9eab1e965d896a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4d0a873c4db436bb2a30507bc2660f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0978563c534b4fb8ea21361b8931e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20617b20eaa94b1aa1678d003274ef11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda9cd1b76464cf5ba70a5cabdbc3437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}